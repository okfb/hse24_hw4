{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rFZS5A_yy1o"
   },
   "source": [
    "# Подготовка файлов и программ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DFpK_Pf1hAX"
   },
   "source": [
    "## Установка HISAT2 (для выравниваия RNA-seq чтений на геном)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WS21uIX63ehw",
    "outputId": "4b7a57e1-5c00-4b21-c92a-a34c12869c43"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (Failed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (Forbidden).)."
     ]
    }
   ],
   "source": [
    "!apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3md6cslv3is6",
    "outputId": "7f2153f1-83ae-4a92-dd85-ecfe71c1bdeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    }
   ],
   "source": [
    "!apt-get install hisat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-Eyz3aD3m8-",
    "outputId": "cd030bc0-ec59-421a-d73d-1bf5ecfd2540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: hisat2: command not found\n"
     ]
    }
   ],
   "source": [
    "!hisat2 --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fTXUIiw2WGQ"
   },
   "source": [
    "## Установка sra-toolkit (для скачивания .fastq файлов из NCBI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5m-7wf_x2Yue",
    "outputId": "49783857-ed30-48cd-b1f8-2a3ee2e35975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  blends-common libkdf5-2 libncbi-vdb2 libncbi-wvdb2 med-config menu\n",
      "Suggested packages:\n",
      "  blends-doc menu-l10n gksu | kde-runtime | ktsuss\n",
      "The following NEW packages will be installed:\n",
      "  blends-common libkdf5-2 libncbi-vdb2 libncbi-wvdb2 med-config menu sra-toolkit\n",
      "0 upgraded, 7 newly installed, 0 to remove and 32 not upgraded.\n",
      "Need to get 8,290 kB of archives.\n",
      "After this operation, 23.0 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 menu amd64 2.1.47ubuntu4 [354 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 blends-common all 0.7.4ubuntu1 [15.9 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libkdf5-2 amd64 2.11.2+dfsg-4build2 [14.7 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libncbi-vdb2 amd64 2.11.2+dfsg-4build2 [1,364 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libncbi-wvdb2 amd64 2.11.2+dfsg-4build2 [1,252 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 sra-toolkit amd64 2.11.3+dfsg-1ubuntu1 [5,277 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 med-config all 3.7.1 [11.6 kB]\n",
      "Fetched 8,290 kB in 2s (4,429 kB/s)\n",
      "Preconfiguring packages ...\n",
      "Selecting previously unselected package menu.\n",
      "(Reading database ... 121080 files and directories currently installed.)\n",
      "Preparing to unpack .../0-menu_2.1.47ubuntu4_amd64.deb ...\n",
      "Unpacking menu (2.1.47ubuntu4) ...\n",
      "Selecting previously unselected package blends-common.\n",
      "Preparing to unpack .../1-blends-common_0.7.4ubuntu1_all.deb ...\n",
      "Unpacking blends-common (0.7.4ubuntu1) ...\n",
      "Selecting previously unselected package libkdf5-2.\n",
      "Preparing to unpack .../2-libkdf5-2_2.11.2+dfsg-4build2_amd64.deb ...\n",
      "Unpacking libkdf5-2 (2.11.2+dfsg-4build2) ...\n",
      "Selecting previously unselected package libncbi-vdb2.\n",
      "Preparing to unpack .../3-libncbi-vdb2_2.11.2+dfsg-4build2_amd64.deb ...\n",
      "Unpacking libncbi-vdb2 (2.11.2+dfsg-4build2) ...\n",
      "Selecting previously unselected package libncbi-wvdb2.\n",
      "Preparing to unpack .../4-libncbi-wvdb2_2.11.2+dfsg-4build2_amd64.deb ...\n",
      "Unpacking libncbi-wvdb2 (2.11.2+dfsg-4build2) ...\n",
      "Selecting previously unselected package sra-toolkit.\n",
      "Preparing to unpack .../5-sra-toolkit_2.11.3+dfsg-1ubuntu1_amd64.deb ...\n",
      "Unpacking sra-toolkit (2.11.3+dfsg-1ubuntu1) ...\n",
      "Selecting previously unselected package med-config.\n",
      "Preparing to unpack .../6-med-config_3.7.1_all.deb ...\n",
      "Unpacking med-config (3.7.1) ...\n",
      "Setting up libncbi-vdb2 (2.11.2+dfsg-4build2) ...\n",
      "Setting up libkdf5-2 (2.11.2+dfsg-4build2) ...\n",
      "Setting up libncbi-wvdb2 (2.11.2+dfsg-4build2) ...\n",
      "Setting up menu (2.1.47ubuntu4) ...\n",
      "Setting up blends-common (0.7.4ubuntu1) ...\n",
      "Setting up sra-toolkit (2.11.3+dfsg-1ubuntu1) ...\n",
      "Setting up med-config (3.7.1) ...\n",
      "Adding group `med' (GID 107) ...\n",
      "Done.\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "Processing triggers for menu (2.1.47ubuntu4) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install sra-toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XiVlP4mfy74q"
   },
   "source": [
    "## Установка FastQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62l1Q2ymbENA",
    "outputId": "2eaf193a-37f8-4799-e8dd-5957b9e26711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: java: command not found\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bpgwFgcbgRd",
    "outputId": "899fb8ca-708f-46e6-f37a-65ef69a315a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-22 03:11:46--  https://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.9.zip\n",
      "Resolving www.bioinformatics.babraham.ac.uk (www.bioinformatics.babraham.ac.uk)... 149.155.133.4\n",
      "Connecting to www.bioinformatics.babraham.ac.uk (www.bioinformatics.babraham.ac.uk)|149.155.133.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10249221 (9.8M) [application/zip]\n",
      "Saving to: ‘fastqc_v0.11.9.zip’\n",
      "\n",
      "fastqc_v0.11.9.zip  100%[===================>]   9.77M  3.81MB/s    in 2.6s    \n",
      "\n",
      "2024-11-22 03:11:49 (3.81 MB/s) - ‘fastqc_v0.11.9.zip’ saved [10249221/10249221]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.9.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTcTjOTJblcm",
    "outputId": "5944616d-4523-4a4e-a854-62a1f11d4b70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  fastqc_v0.11.9.zip\n",
      "  inflating: FastQC/cisd-jhdf5.jar   \n",
      "   creating: FastQC/Configuration/\n",
      "  inflating: FastQC/Configuration/adapter_list.txt  \n",
      "  inflating: FastQC/Configuration/contaminant_list.txt  \n",
      "  inflating: FastQC/Configuration/limits.txt  \n",
      "  inflating: FastQC/fastqc           \n",
      "  inflating: FastQC/fastqc_icon.ico  \n",
      "   creating: FastQC/Help/\n",
      "   creating: FastQC/Help/1 Introduction/\n",
      "   creating: FastQC/Help/1 Introduction/.svn/\n",
      "  inflating: FastQC/Help/1 Introduction/.svn/entries  \n",
      "   creating: FastQC/Help/1 Introduction/.svn/props/\n",
      "   creating: FastQC/Help/1 Introduction/.svn/text-base/\n",
      "  inflating: FastQC/Help/1 Introduction/.svn/text-base/1.1 What is FastQC.html.svn-base  \n",
      "   creating: FastQC/Help/1 Introduction/.svn/tmp/\n",
      "   creating: FastQC/Help/1 Introduction/.svn/tmp/props/\n",
      "  inflating: FastQC/Help/1 Introduction/1.1 What is FastQC.html  \n",
      "   creating: FastQC/Help/2 Basic Operations/\n",
      "   creating: FastQC/Help/2 Basic Operations/.svn/\n",
      "  inflating: FastQC/Help/2 Basic Operations/.svn/entries  \n",
      "   creating: FastQC/Help/2 Basic Operations/.svn/props/\n",
      "   creating: FastQC/Help/2 Basic Operations/.svn/text-base/\n",
      "  inflating: FastQC/Help/2 Basic Operations/.svn/text-base/2.1 Opening a sequence file.html.svn-base  \n",
      "  inflating: FastQC/Help/2 Basic Operations/.svn/text-base/2.2 Evaluating Results.html.svn-base  \n",
      "  inflating: FastQC/Help/2 Basic Operations/.svn/text-base/2.3 Saving a Report.html.svn-base  \n",
      "   creating: FastQC/Help/2 Basic Operations/.svn/tmp/\n",
      "   creating: FastQC/Help/2 Basic Operations/.svn/tmp/props/\n",
      "  inflating: FastQC/Help/2 Basic Operations/2.1 Opening a sequence file.html  \n",
      "  inflating: FastQC/Help/2 Basic Operations/2.2 Evaluating Results.html  \n",
      "  inflating: FastQC/Help/2 Basic Operations/2.3 Saving a Report.html  \n",
      "   creating: FastQC/Help/3 Analysis Modules/\n",
      "   creating: FastQC/Help/3 Analysis Modules/.svn/\n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/entries  \n",
      "   creating: FastQC/Help/3 Analysis Modules/.svn/prop-base/\n",
      " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/duplication_levels.png.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/prop-base/kmer_profiles.png.svn-base  \n",
      " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_gc_content.png.svn-base  \n",
      " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_n_content.png.svn-base  \n",
      " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_quality.png.svn-base  \n",
      " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_sequence_content.png.svn-base  \n",
      " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_sequence_gc_content.png.svn-base  \n",
      " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_sequence_quality.png.svn-base  \n",
      " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_tile_quality.png.svn-base  \n",
      " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/sequence_length_distribution.png.svn-base  \n",
      "   creating: FastQC/Help/3 Analysis Modules/.svn/props/\n",
      "   creating: FastQC/Help/3 Analysis Modules/.svn/text-base/\n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/1 Basic Statistics.html.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/10 Adapter Content.html.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/11 Kmer Content.html.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/12 Per Tile Sequence Quality.html.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/2 Per Base Sequence Quality.html.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/3 Per Sequence Quality Scores.html.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/4 Per Base Sequence Content.html.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/5 Per Sequence GC Content.html.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/6 Per Base N Content.html.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/7 Sequence Length Distribution.html.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/8 Duplicate Sequences.html.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/9 Overrepresented Sequences.html.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/duplication_levels.png.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/kmer_profiles.png.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_gc_content.png.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_n_content.png.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_quality.png.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_sequence_content.png.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_sequence_gc_content.png.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_sequence_quality.png.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_tile_quality.png.svn-base  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/sequence_length_distribution.png.svn-base  \n",
      "   creating: FastQC/Help/3 Analysis Modules/.svn/tmp/\n",
      "   creating: FastQC/Help/3 Analysis Modules/.svn/tmp/props/\n",
      "  inflating: FastQC/Help/3 Analysis Modules/1 Basic Statistics.html  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/10 Adapter Content.html  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/11 Kmer Content.html  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/12 Per Tile Sequence Quality.html  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/2 Per Base Sequence Quality.html  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/3 Per Sequence Quality Scores.html  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/4 Per Base Sequence Content.html  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/5 Per Sequence GC Content.html  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/6 Per Base N Content.html  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/7 Sequence Length Distribution.html  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/8 Duplicate Sequences.html  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/9 Overrepresented Sequences.html  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/duplication_levels.png  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/kmer_profiles.png  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/per_base_gc_content.png  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/per_base_n_content.png  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/per_base_quality.png  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/per_base_sequence_content.png  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/per_sequence_gc_content.png  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/per_sequence_quality.png  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/per_tile_quality.png  \n",
      "  inflating: FastQC/Help/3 Analysis Modules/sequence_length_distribution.png  \n",
      "  inflating: FastQC/INSTALL.txt      \n",
      "  inflating: FastQC/jbzip2-0.9.jar   \n",
      "  inflating: FastQC/LICENSE          \n",
      "  inflating: FastQC/LICENSE.txt      \n",
      "  inflating: FastQC/LICENSE_JHDF5.txt  \n",
      "   creating: FastQC/net/\n",
      "   creating: FastQC/net/sourceforge/\n",
      "   creating: FastQC/net/sourceforge/iharder/\n",
      "   creating: FastQC/net/sourceforge/iharder/base64/\n",
      "  inflating: FastQC/net/sourceforge/iharder/base64/Base64$1.class  \n",
      "  inflating: FastQC/net/sourceforge/iharder/base64/Base64$InputStream.class  \n",
      "  inflating: FastQC/net/sourceforge/iharder/base64/Base64$OutputStream.class  \n",
      "  inflating: FastQC/net/sourceforge/iharder/base64/Base64.class  \n",
      "   creating: FastQC/org/\n",
      "   creating: FastQC/org/apache/\n",
      "   creating: FastQC/org/apache/commons/\n",
      "   creating: FastQC/org/apache/commons/math3/\n",
      "   creating: FastQC/org/apache/commons/math3/analysis/\n",
      "   creating: FastQC/org/apache/commons/math3/analysis/solvers/\n",
      "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/AbstractUnivariateSolver.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/AllowedSolution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BaseAbstractUnivariateSolver.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BaseUnivariateSolver.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BracketedUnivariateSolver.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BrentSolver.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/UnivariateSolver.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/UnivariateSolverUtils.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/analysis/UnivariateFunction.class  \n",
      "   creating: FastQC/org/apache/commons/math3/distribution/\n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/AbstractIntegerDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/AbstractRealDistribution$1.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/AbstractRealDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/BetaDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/BinomialDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/CauchyDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/ChiSquaredDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/FDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/GammaDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/HypergeometricDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/IntegerDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/NormalDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/PascalDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/PoissonDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/RealDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/SaddlePointExpansion.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/TDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/WeibullDistribution.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/distribution/ZipfDistribution.class  \n",
      "   creating: FastQC/org/apache/commons/math3/exception/\n",
      "  inflating: FastQC/org/apache/commons/math3/exception/ConvergenceException.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/DimensionMismatchException.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/MathArithmeticException.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/MathIllegalArgumentException.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/MathIllegalNumberException.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/MathIllegalStateException.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/MathInternalError.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/MaxCountExceededException.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/NoBracketingException.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/NotFiniteNumberException.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/NotPositiveException.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/NotStrictlyPositiveException.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/NullArgumentException.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/NumberIsTooLargeException.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/NumberIsTooSmallException.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/OutOfRangeException.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/TooManyEvaluationsException.class  \n",
      "   creating: FastQC/org/apache/commons/math3/exception/util/\n",
      "  inflating: FastQC/org/apache/commons/math3/exception/util/ArgUtils.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/util/ExceptionContext.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/util/ExceptionContextProvider.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/util/Localizable.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/exception/util/LocalizedFormats.class  \n",
      "   creating: FastQC/org/apache/commons/math3/random/\n",
      "  inflating: FastQC/org/apache/commons/math3/random/AbstractWell.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/random/BitsStreamGenerator.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/random/RandomData.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/random/RandomDataImpl.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/random/RandomGenerator.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/random/Well19937c.class  \n",
      "   creating: FastQC/org/apache/commons/math3/special/\n",
      "  inflating: FastQC/org/apache/commons/math3/special/Beta$1.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/special/Beta.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/special/Erf.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/special/Gamma$1.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/special/Gamma.class  \n",
      "   creating: FastQC/org/apache/commons/math3/util/\n",
      "  inflating: FastQC/org/apache/commons/math3/util/ArithmeticUtils.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/util/ContinuedFraction.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/util/DoubleArray.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/util/FastMath$ExpFracTable.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/util/FastMath$ExpIntTable.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/util/FastMath$lnMant.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/util/FastMath.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/util/FastMathCalc.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/util/FastMathLiteralArrays.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/util/Incrementor$1.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/util/Incrementor$MaxCountExceededCallback.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/util/Incrementor.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/util/MathUtils.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/util/Precision.class  \n",
      "  inflating: FastQC/org/apache/commons/math3/util/ResizableDoubleArray.class  \n",
      "  inflating: FastQC/README.md        \n",
      "  inflating: FastQC/README.txt       \n",
      "  inflating: FastQC/RELEASE_NOTES.txt  \n",
      "  inflating: FastQC/run_fastqc.bat   \n",
      "  inflating: FastQC/sam-1.103.jar    \n",
      "   creating: FastQC/Templates/\n",
      "  inflating: FastQC/Templates/fastqc2fo.xsl  \n",
      "  inflating: FastQC/Templates/header_template.html  \n",
      "   creating: FastQC/Templates/Icons/\n",
      " extracting: FastQC/Templates/Icons/error.png  \n",
      " extracting: FastQC/Templates/Icons/fastqc_icon.png  \n",
      " extracting: FastQC/Templates/Icons/tick.png  \n",
      " extracting: FastQC/Templates/Icons/warning.png  \n",
      "   creating: FastQC/uk/\n",
      "   creating: FastQC/uk/ac/\n",
      "   creating: FastQC/uk/ac/babraham/\n",
      "   creating: FastQC/uk/ac/babraham/FastQC/\n",
      "   creating: FastQC/uk/ac/babraham/FastQC/Analysis/\n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/AnalysisListener.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/AnalysisQueue.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/AnalysisRunner.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/OfflineRunner.class  \n",
      "   creating: FastQC/uk/ac/babraham/FastQC/Dialogs/\n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/AboutDialog$1.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/AboutDialog.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/FastQCTitlePanel$SmoothJLabel.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/FastQCTitlePanel.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/WelcomePanel.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCApplication$1.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCApplication.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCConfig.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCMenuBar.class  \n",
      "   creating: FastQC/uk/ac/babraham/FastQC/FileFilters/\n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/BAMFileFilter.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/CasavaFastQFileFilter.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/FastQFileFilter.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/GobyFileFilter.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/MappedBAMFileFilter.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/SequenceFileFilter.class  \n",
      "   creating: FastQC/uk/ac/babraham/FastQC/Graphs/\n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/BaseGroup.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/LineGraph.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/QualityBoxPlot.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/TileGraph.class  \n",
      "   creating: FastQC/uk/ac/babraham/FastQC/Help/\n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpDialog.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpIndexRoot$FileSorter.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpIndexRoot.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpPage.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpPageDisplay$HelpEditor.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpPageDisplay.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpSearchPanel.class  \n",
      "   creating: FastQC/uk/ac/babraham/FastQC/Modules/\n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AbstractQCModule.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AdapterContent$Adapter.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AdapterContent$ResultsTable.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AdapterContent.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/BasicStats$ResultsTable.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/BasicStats.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/DuplicationLevel.class  \n",
      "   creating: FastQC/uk/ac/babraham/FastQC/Modules/GCModel/\n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/GCModel/GCModel.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/GCModel/GCModelValue.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/KmerContent$Kmer.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/KmerContent$ResultsTable.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/KmerContent.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/ModuleConfig.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/ModuleFactory.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/NContent.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/OverRepresentedSeqs$OverrepresentedSeq.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/OverRepresentedSeqs$ResultsTable.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/OverRepresentedSeqs.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerBaseQualityScores.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerBaseSequenceContent.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerSequenceGCContent.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerSequenceQualityScores.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerTileQualityScores.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/QCModule.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/SequenceLengthDistribution.class  \n",
      "   creating: FastQC/uk/ac/babraham/FastQC/Report/\n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Report/HTMLReportArchive.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Report/stylesheet.txt  \n",
      "   creating: FastQC/uk/ac/babraham/FastQC/Resources/\n",
      " extracting: FastQC/uk/ac/babraham/FastQC/Resources/error.png  \n",
      " extracting: FastQC/uk/ac/babraham/FastQC/Resources/fastqc_icon.png  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Resources/fastqc_icon.svg  \n",
      " extracting: FastQC/uk/ac/babraham/FastQC/Resources/fastqc_icon_100.png  \n",
      " extracting: FastQC/uk/ac/babraham/FastQC/Resources/tick.png  \n",
      " extracting: FastQC/uk/ac/babraham/FastQC/Resources/warning.png  \n",
      "   creating: FastQC/uk/ac/babraham/FastQC/Results/\n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Results/ResultsPanel$ModuleRenderer.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Results/ResultsPanel.class  \n",
      "   creating: FastQC/uk/ac/babraham/FastQC/Sequence/\n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/BAMFile.class  \n",
      "   creating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/\n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/Contaminant.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/ContaminantHit.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/ContaminentFinder.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Fast5File.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/FastQFile.class  \n",
      "   creating: FastQC/uk/ac/babraham/FastQC/Sequence/QualityEncoding/\n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/QualityEncoding/PhredEncoding.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Sequence.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFactory.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFile.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFileGroup.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFormatException.class  \n",
      "   creating: FastQC/uk/ac/babraham/FastQC/Statistics/\n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Statistics/NormalDistribution.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Statistics/PearsonCorrelation.class  \n",
      "   creating: FastQC/uk/ac/babraham/FastQC/Utilities/\n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/CasavaBasename.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/HotColdColourGradient.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/ImageToBase64.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/MultiMemberGZIPInputStream.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/NameFormatException.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/NanoporeBasename.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/QualityCount.class  \n",
      "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/RGB.class  \n"
     ]
    }
   ],
   "source": [
    "!unzip fastqc_v0.11.9.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "S79LH0aXbvLx"
   },
   "outputs": [],
   "source": [
    "!chmod a+x FastQC/fastqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PsLuZDt4b7jT",
    "outputId": "8584e30b-f5c5-402d-f0b7-c7ecba524d8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            FastQC - A high throughput sequence QC analysis tool\n",
      "\n",
      "SYNOPSIS\n",
      "\n",
      "\tfastqc seqfile1 seqfile2 .. seqfileN\n",
      "\n",
      "    fastqc [-o output dir] [--(no)extract] [-f fastq|bam|sam] \n",
      "           [-c contaminant file] seqfile1 .. seqfileN\n",
      "\n",
      "DESCRIPTION\n",
      "\n",
      "    FastQC reads a set of sequence files and produces from each one a quality\n",
      "    control report consisting of a number of different modules, each one of \n",
      "    which will help to identify a different potential type of problem in your\n",
      "    data.\n",
      "    \n",
      "    If no files to process are specified on the command line then the program\n",
      "    will start as an interactive graphical application.  If files are provided\n",
      "    on the command line then the program will run with no user interaction\n",
      "    required.  In this mode it is suitable for inclusion into a standardised\n",
      "    analysis pipeline.\n",
      "    \n",
      "    The options for the program as as follows:\n",
      "    \n",
      "    -h --help       Print this help file and exit\n",
      "    \n",
      "    -v --version    Print the version of the program and exit\n",
      "    \n",
      "    -o --outdir     Create all output files in the specified output directory.\n",
      "                    Please note that this directory must exist as the program\n",
      "                    will not create it.  If this option is not set then the \n",
      "                    output file for each sequence file is created in the same\n",
      "                    directory as the sequence file which was processed.\n",
      "                    \n",
      "    --casava        Files come from raw casava output. Files in the same sample\n",
      "                    group (differing only by the group number) will be analysed\n",
      "                    as a set rather than individually. Sequences with the filter\n",
      "                    flag set in the header will be excluded from the analysis.\n",
      "                    Files must have the same names given to them by casava\n",
      "                    (including being gzipped and ending with .gz) otherwise they\n",
      "                    won't be grouped together correctly.\n",
      "                    \n",
      "    --nano          Files come from nanopore sequences and are in fast5 format. In\n",
      "                    this mode you can pass in directories to process and the program\n",
      "                    will take in all fast5 files within those directories and produce\n",
      "                    a single output file from the sequences found in all files.                    \n",
      "                    \n",
      "    --nofilter      If running with --casava then don't remove read flagged by\n",
      "                    casava as poor quality when performing the QC analysis.\n",
      "                   \n",
      "    --extract       If set then the zipped output file will be uncompressed in\n",
      "                    the same directory after it has been created.  By default\n",
      "                    this option will be set if fastqc is run in non-interactive\n",
      "                    mode.\n",
      "                    \n",
      "    -j --java       Provides the full path to the java binary you want to use to\n",
      "                    launch fastqc. If not supplied then java is assumed to be in\n",
      "                    your path.\n",
      "                   \n",
      "    --noextract     Do not uncompress the output file after creating it.  You\n",
      "                    should set this option if you do not wish to uncompress\n",
      "                    the output when running in non-interactive mode.\n",
      "                    \n",
      "    --nogroup       Disable grouping of bases for reads >50bp. All reports will\n",
      "                    show data for every base in the read.  WARNING: Using this\n",
      "                    option will cause fastqc to crash and burn if you use it on\n",
      "                    really long reads, and your plots may end up a ridiculous size.\n",
      "                    You have been warned!\n",
      "                    \n",
      "    --min_length    Sets an artificial lower limit on the length of the sequence\n",
      "                    to be shown in the report.  As long as you set this to a value\n",
      "                    greater or equal to your longest read length then this will be\n",
      "                    the sequence length used to create your read groups.  This can\n",
      "                    be useful for making directly comaparable statistics from \n",
      "                    datasets with somewhat variable read lengths.\n",
      "                    \n",
      "    -f --format     Bypasses the normal sequence file format detection and\n",
      "                    forces the program to use the specified format.  Valid\n",
      "                    formats are bam,sam,bam_mapped,sam_mapped and fastq\n",
      "                    \n",
      "    -t --threads    Specifies the number of files which can be processed\n",
      "                    simultaneously.  Each thread will be allocated 250MB of\n",
      "                    memory so you shouldn't run more threads than your\n",
      "                    available memory will cope with, and not more than\n",
      "                    6 threads on a 32 bit machine\n",
      "                  \n",
      "    -c              Specifies a non-default file which contains the list of\n",
      "    --contaminants  contaminants to screen overrepresented sequences against.\n",
      "                    The file must contain sets of named contaminants in the\n",
      "                    form name[tab]sequence.  Lines prefixed with a hash will\n",
      "                    be ignored.\n",
      "\n",
      "    -a              Specifies a non-default file which contains the list of\n",
      "    --adapters      adapter sequences which will be explicity searched against\n",
      "                    the library. The file must contain sets of named adapters\n",
      "                    in the form name[tab]sequence.  Lines prefixed with a hash\n",
      "                    will be ignored.\n",
      "                    \n",
      "    -l              Specifies a non-default file which contains a set of criteria\n",
      "    --limits        which will be used to determine the warn/error limits for the\n",
      "                    various modules.  This file can also be used to selectively \n",
      "                    remove some modules from the output all together.  The format\n",
      "                    needs to mirror the default limits.txt file found in the\n",
      "                    Configuration folder.\n",
      "                    \n",
      "   -k --kmers       Specifies the length of Kmer to look for in the Kmer content\n",
      "                    module. Specified Kmer length must be between 2 and 10. Default\n",
      "                    length is 7 if not specified.\n",
      "                    \n",
      "   -q --quiet       Supress all progress messages on stdout and only report errors.\n",
      "   \n",
      "   -d --dir         Selects a directory to be used for temporary files written when\n",
      "                    generating report images. Defaults to system temp directory if\n",
      "                    not specified.\n",
      "                    \n",
      "BUGS\n",
      "\n",
      "    Any bugs in fastqc should be reported either to simon.andrews@babraham.ac.uk\n",
      "    or in www.bioinformatics.babraham.ac.uk/bugzilla/\n",
      "                   \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "!./FastQC/fastqc --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dqWpZZ_0_V-"
   },
   "source": [
    "## Установка HTSeq-count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_yqggdMhMfj",
    "outputId": "8b922470-e010-4c85-f269-693fc862a57b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting HTSeq\n",
      "  Downloading HTSeq-2.0.9-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy in /home/auser/anaconda3/lib/python3.12/site-packages (from HTSeq) (1.26.4)\n",
      "Collecting pysam (from HTSeq)\n",
      "  Downloading pysam-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Downloading HTSeq-2.0.9-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pysam-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl (25.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.2/25.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: pysam, HTSeq\n",
      "Successfully installed HTSeq-2.0.9 pysam-0.22.1\n"
     ]
    }
   ],
   "source": [
    "!pip install HTSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7W0Ep2nhT_d",
    "outputId": "b84dd4f8-882f-4e84-bb27-e1ea72621f6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.9\n"
     ]
    }
   ],
   "source": [
    "!htseq-count --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6MhDf5N2tQ3"
   },
   "source": [
    "## Скачиваем RNA-seq данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LicIlxo028wE"
   },
   "source": [
    "* Контрольные образцы:\t\tSRR3414635, SRR3414636, SRR3414637\n",
    "* Перепрограммированные образцы: \tSRR3414629, SRR3414630, SRR3414631\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7-OCZli2z38",
    "outputId": "06fb15a2-3f36-45ec-f340-64abf06d645f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 20956475 spots for SRR3414635\n",
      "Written 20956475 spots for SRR3414635\n",
      "\n",
      "real\t26m31.098s\n",
      "user\t1m41.548s\n",
      "sys\t0m13.513s\n"
     ]
    }
   ],
   "source": [
    "!time  fastq-dump  --split-files  SRR3414635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ik5ouc98l0l",
    "outputId": "28bcdea6-ba79-42fc-e1c0-8970fdbed816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 20307147 spots for SRR3414636\n",
      "Written 20307147 spots for SRR3414636\n"
     ]
    }
   ],
   "source": [
    "!fastq-dump  --split-files  SRR3414636"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qckxtRmb8lp7",
    "outputId": "08bd075f-eda6-491e-9b6b-c176e34cc27b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 20385570 spots for SRR3414637\n",
      "Written 20385570 spots for SRR3414637\n",
      "\n",
      "real\t22m4.608s\n",
      "user\t1m35.111s\n",
      "sys\t0m11.325s\n"
     ]
    }
   ],
   "source": [
    "!time  fastq-dump  --split-files  SRR3414637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUW98fUg8lf5",
    "outputId": "9c6715ed-0fb2-423c-e6de-9bcef8b2270a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 21106089 spots for SRR3414629\n",
      "Written 21106089 spots for SRR3414629\n",
      "\n",
      "real\t22m47.264s\n",
      "user\t1m40.282s\n",
      "sys\t0m27.097s\n"
     ]
    }
   ],
   "source": [
    "!time  fastq-dump  --split-files  SRR3414629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tSN-QLVP8lJU",
    "outputId": "1ea50f8c-d7b5-4650-c7f4-49fb5c1ca8d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 15244711 spots for SRR3414630\n",
      "Written 15244711 spots for SRR3414630\n",
      "\n",
      "real\t16m43.317s\n",
      "user\t1m12.938s\n",
      "sys\t0m29.894s\n"
     ]
    }
   ],
   "source": [
    "!time  fastq-dump  --split-files  SRR3414630"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ww3fdhHN8kSP",
    "outputId": "157cee67-b52e-4218-a1b5-cacce51bc6ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 24244069 spots for SRR3414631\n",
      "Written 24244069 spots for SRR3414631\n",
      "\n",
      "real\t30m39.799s\n",
      "user\t1m53.915s\n",
      "sys\t0m36.738s\n"
     ]
    }
   ],
   "source": [
    "!time  fastq-dump  --split-files  SRR3414631"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAn1rivS0BME"
   },
   "source": [
    "## Скачиваем геном мыши mm10 (проиндексированный для HISAT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWfSQMGZ03Ch",
    "outputId": "c5b64da3-b757-44c4-daa8-0c62818fd1b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-22 06:05:56--  https://genome-idx.s3.amazonaws.com/hisat/mm10_genome.tar.gz\n",
      "Resolving genome-idx.s3.amazonaws.com (genome-idx.s3.amazonaws.com)... 3.5.25.50, 52.216.32.129, 52.216.54.33, ...\n",
      "Connecting to genome-idx.s3.amazonaws.com (genome-idx.s3.amazonaws.com)|3.5.25.50|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3804366597 (3.5G) [binary/octet-stream]\n",
      "Saving to: ‘mm10_genome.tar.gz’\n",
      "\n",
      "mm10_genome.tar.gz  100%[===================>]   3.54G  9.74MB/s    in 20m 31s \n",
      "\n",
      "2024-11-22 06:26:29 (2.95 MB/s) - ‘mm10_genome.tar.gz’ saved [3804366597/3804366597]\n",
      "\n",
      "mm10/\n",
      "mm10/genome.8.ht2\n",
      "mm10/genome.5.ht2\n",
      "mm10/make_mm10.sh\n",
      "mm10/genome.7.ht2\n",
      "mm10/genome.6.ht2\n",
      "mm10/genome.4.ht2\n",
      "mm10/genome.3.ht2\n",
      "mm10/genome.1.ht2\n",
      "mm10/genome.2.ht2\n"
     ]
    }
   ],
   "source": [
    "!wget https://genome-idx.s3.amazonaws.com/hisat/mm10_genome.tar.gz\n",
    "!tar -xzvf mm10_genome.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGULD5P70tvT"
   },
   "source": [
    "## Скачиваем аннотацию генов GENCODE для генома мыши mm10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8SxMZMC3Aw-",
    "outputId": "1234aa18-5e01-4e0d-b625-4bcb30f336de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-22 06:27:06--  http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz\n",
      "Resolving ftp.ebi.ac.uk (ftp.ebi.ac.uk)... 193.62.193.165\n",
      "Connecting to ftp.ebi.ac.uk (ftp.ebi.ac.uk)|193.62.193.165|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 28542432 (27M) [application/x-gzip]\n",
      "Saving to: ‘gencode.vM25.annotation.gtf.gz’\n",
      "\n",
      "gencode.vM25.annota 100%[===================>]  27.22M  3.48MB/s    in 9.1s    \n",
      "\n",
      "2024-11-22 06:27:21 (2.98 MB/s) - ‘gencode.vM25.annotation.gtf.gz’ saved [28542432/28542432]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz\n",
    "!gzip -d gencode.vM25.annotation.gtf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzucvMQkzzs9"
   },
   "source": [
    "# Выравниваем чтения и скачиваем отчет MultiQC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRBfl7NL3xgN"
   },
   "source": [
    "* Для каждого образца запускаем FastQC. Скачиваем полученные html файлы и проверяем есть ли проблемы с файлами. Можно также установить multiqc и получить объединенный .html файл. Полученные результаты приводим в отчете на Github-е.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABkz3YC8cjhD",
    "outputId": "1f0d48f4-7f4e-41e1-c302-540702343b05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR3414635_1.fastq\n",
      "Approx 5% complete for SRR3414635_1.fastq\n",
      "Approx 10% complete for SRR3414635_1.fastq\n",
      "Approx 15% complete for SRR3414635_1.fastq\n",
      "Approx 20% complete for SRR3414635_1.fastq\n",
      "Approx 25% complete for SRR3414635_1.fastq\n",
      "Approx 30% complete for SRR3414635_1.fastq\n",
      "Approx 35% complete for SRR3414635_1.fastq\n",
      "Approx 40% complete for SRR3414635_1.fastq\n",
      "Approx 45% complete for SRR3414635_1.fastq\n",
      "Approx 50% complete for SRR3414635_1.fastq\n",
      "Approx 55% complete for SRR3414635_1.fastq\n",
      "Approx 60% complete for SRR3414635_1.fastq\n",
      "Approx 65% complete for SRR3414635_1.fastq\n",
      "Approx 70% complete for SRR3414635_1.fastq\n",
      "Approx 75% complete for SRR3414635_1.fastq\n",
      "Approx 80% complete for SRR3414635_1.fastq\n",
      "Approx 85% complete for SRR3414635_1.fastq\n",
      "Approx 90% complete for SRR3414635_1.fastq\n",
      "Approx 95% complete for SRR3414635_1.fastq\n",
      "Analysis complete for SRR3414635_1.fastq\n"
     ]
    }
   ],
   "source": [
    "!./FastQC/fastqc  SRR3414635_1.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oXoaAJG-Fvn",
    "outputId": "6839af86-aab9-4dad-f48c-606709d9efd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR3414636_1.fastq\n",
      "Approx 5% complete for SRR3414636_1.fastq\n",
      "Approx 10% complete for SRR3414636_1.fastq\n",
      "Approx 15% complete for SRR3414636_1.fastq\n",
      "Approx 20% complete for SRR3414636_1.fastq\n",
      "Approx 25% complete for SRR3414636_1.fastq\n",
      "Approx 30% complete for SRR3414636_1.fastq\n",
      "Approx 35% complete for SRR3414636_1.fastq\n",
      "Approx 40% complete for SRR3414636_1.fastq\n",
      "Approx 45% complete for SRR3414636_1.fastq\n",
      "Approx 50% complete for SRR3414636_1.fastq\n",
      "Approx 55% complete for SRR3414636_1.fastq\n",
      "Approx 60% complete for SRR3414636_1.fastq\n",
      "Approx 65% complete for SRR3414636_1.fastq\n",
      "Approx 70% complete for SRR3414636_1.fastq\n",
      "Approx 75% complete for SRR3414636_1.fastq\n",
      "Approx 80% complete for SRR3414636_1.fastq\n",
      "Approx 85% complete for SRR3414636_1.fastq\n",
      "Approx 90% complete for SRR3414636_1.fastq\n",
      "Approx 95% complete for SRR3414636_1.fastq\n",
      "Analysis complete for SRR3414636_1.fastq\n"
     ]
    }
   ],
   "source": [
    "!./FastQC/fastqc  SRR3414636_1.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-bpynqH3-G7V",
    "outputId": "0aa3feaf-9e3c-412e-851b-20d6590a1eda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR3414637_1.fastq\n",
      "Approx 5% complete for SRR3414637_1.fastq\n",
      "Approx 10% complete for SRR3414637_1.fastq\n",
      "Approx 15% complete for SRR3414637_1.fastq\n",
      "Approx 20% complete for SRR3414637_1.fastq\n",
      "Approx 25% complete for SRR3414637_1.fastq\n",
      "Approx 30% complete for SRR3414637_1.fastq\n",
      "Approx 35% complete for SRR3414637_1.fastq\n",
      "Approx 40% complete for SRR3414637_1.fastq\n",
      "Approx 45% complete for SRR3414637_1.fastq\n",
      "Approx 50% complete for SRR3414637_1.fastq\n",
      "Approx 55% complete for SRR3414637_1.fastq\n",
      "Approx 60% complete for SRR3414637_1.fastq\n",
      "Approx 65% complete for SRR3414637_1.fastq\n",
      "Approx 70% complete for SRR3414637_1.fastq\n",
      "Approx 75% complete for SRR3414637_1.fastq\n",
      "Approx 80% complete for SRR3414637_1.fastq\n",
      "Approx 85% complete for SRR3414637_1.fastq\n",
      "Approx 90% complete for SRR3414637_1.fastq\n",
      "Approx 95% complete for SRR3414637_1.fastq\n",
      "Analysis complete for SRR3414637_1.fastq\n"
     ]
    }
   ],
   "source": [
    "!./FastQC/fastqc  SRR3414637_1.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdBLvlSL-Gv3",
    "outputId": "438e645a-57d4-45f6-9bb8-1f40f83d76e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR3414629_1.fastq\n",
      "Approx 5% complete for SRR3414629_1.fastq\n",
      "Approx 10% complete for SRR3414629_1.fastq\n",
      "Approx 15% complete for SRR3414629_1.fastq\n",
      "Approx 20% complete for SRR3414629_1.fastq\n",
      "Approx 25% complete for SRR3414629_1.fastq\n",
      "Approx 30% complete for SRR3414629_1.fastq\n",
      "Approx 35% complete for SRR3414629_1.fastq\n",
      "Approx 40% complete for SRR3414629_1.fastq\n",
      "Approx 45% complete for SRR3414629_1.fastq\n",
      "Approx 50% complete for SRR3414629_1.fastq\n",
      "Approx 55% complete for SRR3414629_1.fastq\n",
      "Approx 60% complete for SRR3414629_1.fastq\n",
      "Approx 65% complete for SRR3414629_1.fastq\n",
      "Approx 70% complete for SRR3414629_1.fastq\n",
      "Approx 75% complete for SRR3414629_1.fastq\n",
      "Approx 80% complete for SRR3414629_1.fastq\n",
      "Approx 85% complete for SRR3414629_1.fastq\n",
      "Approx 90% complete for SRR3414629_1.fastq\n",
      "Approx 95% complete for SRR3414629_1.fastq\n",
      "Analysis complete for SRR3414629_1.fastq\n"
     ]
    }
   ],
   "source": [
    "!./FastQC/fastqc  SRR3414629_1.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FO0qj7MA-Gjd",
    "outputId": "6a23beb2-c2bf-4d0c-8a72-b2516cdc68a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR3414630_1.fastq\n",
      "Approx 5% complete for SRR3414630_1.fastq\n",
      "Approx 10% complete for SRR3414630_1.fastq\n",
      "Approx 15% complete for SRR3414630_1.fastq\n",
      "Approx 20% complete for SRR3414630_1.fastq\n",
      "Approx 25% complete for SRR3414630_1.fastq\n",
      "Approx 30% complete for SRR3414630_1.fastq\n",
      "Approx 35% complete for SRR3414630_1.fastq\n",
      "Approx 40% complete for SRR3414630_1.fastq\n",
      "Approx 45% complete for SRR3414630_1.fastq\n",
      "Approx 50% complete for SRR3414630_1.fastq\n",
      "Approx 55% complete for SRR3414630_1.fastq\n",
      "Approx 60% complete for SRR3414630_1.fastq\n",
      "Approx 65% complete for SRR3414630_1.fastq\n",
      "Approx 70% complete for SRR3414630_1.fastq\n",
      "Approx 75% complete for SRR3414630_1.fastq\n",
      "Approx 80% complete for SRR3414630_1.fastq\n",
      "Approx 85% complete for SRR3414630_1.fastq\n",
      "Approx 90% complete for SRR3414630_1.fastq\n",
      "Approx 95% complete for SRR3414630_1.fastq\n",
      "Analysis complete for SRR3414630_1.fastq\n"
     ]
    }
   ],
   "source": [
    "!./FastQC/fastqc  SRR3414630_1.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_28fvcpG-GS-",
    "outputId": "5af074db-9d96-43b5-e3c7-a0cc645027e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR3414631_1.fastq\n",
      "Approx 5% complete for SRR3414631_1.fastq\n",
      "Approx 10% complete for SRR3414631_1.fastq\n",
      "Approx 15% complete for SRR3414631_1.fastq\n",
      "Approx 20% complete for SRR3414631_1.fastq\n",
      "Approx 25% complete for SRR3414631_1.fastq\n",
      "Approx 30% complete for SRR3414631_1.fastq\n",
      "Approx 35% complete for SRR3414631_1.fastq\n",
      "Approx 40% complete for SRR3414631_1.fastq\n",
      "Approx 45% complete for SRR3414631_1.fastq\n",
      "Approx 50% complete for SRR3414631_1.fastq\n",
      "Approx 55% complete for SRR3414631_1.fastq\n",
      "Approx 60% complete for SRR3414631_1.fastq\n",
      "Approx 65% complete for SRR3414631_1.fastq\n",
      "Approx 70% complete for SRR3414631_1.fastq\n",
      "Approx 75% complete for SRR3414631_1.fastq\n",
      "Approx 80% complete for SRR3414631_1.fastq\n",
      "Approx 85% complete for SRR3414631_1.fastq\n",
      "Approx 90% complete for SRR3414631_1.fastq\n",
      "Approx 95% complete for SRR3414631_1.fastq\n",
      "Analysis complete for SRR3414631_1.fastq\n"
     ]
    }
   ],
   "source": [
    "!./FastQC/fastqc  SRR3414631_1.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aC04Ftx9Gss8",
    "outputId": "5abac751-3a71-46ed-9996-3bd02c34876f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting multiqc\n",
      "  Using cached multiqc-1.25.2-py3-none-any.whl.metadata (45 kB)\n",
      "Requirement already satisfied: click in /home/auser/anaconda3/lib/python3.12/site-packages (from multiqc) (8.1.7)\n",
      "Collecting humanize (from multiqc)\n",
      "  Using cached humanize-4.11.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: importlib-metadata in /home/auser/anaconda3/lib/python3.12/site-packages (from multiqc) (7.0.1)\n",
      "Requirement already satisfied: jinja2>=3.0.0 in /home/auser/anaconda3/lib/python3.12/site-packages (from multiqc) (3.1.4)\n",
      "Collecting kaleido==0.2.1 (from multiqc)\n",
      "  Using cached kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: markdown in /home/auser/anaconda3/lib/python3.12/site-packages (from multiqc) (3.4.1)\n",
      "Requirement already satisfied: numpy in /home/auser/anaconda3/lib/python3.12/site-packages (from multiqc) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/auser/anaconda3/lib/python3.12/site-packages (from multiqc) (24.2)\n",
      "Requirement already satisfied: requests in /home/auser/anaconda3/lib/python3.12/site-packages (from multiqc) (2.32.3)\n",
      "Requirement already satisfied: Pillow>=10 in /home/auser/anaconda3/lib/python3.12/site-packages (from multiqc) (10.3.0)\n",
      "Requirement already satisfied: plotly>=5.18 in /home/auser/anaconda3/lib/python3.12/site-packages (from multiqc) (5.22.0)\n",
      "Requirement already satisfied: pyyaml>=4 in /home/auser/anaconda3/lib/python3.12/site-packages (from multiqc) (6.0.2)\n",
      "Requirement already satisfied: rich>=10 in /home/auser/anaconda3/lib/python3.12/site-packages (from multiqc) (13.3.5)\n",
      "Collecting rich-click (from multiqc)\n",
      "  Using cached rich_click-1.8.4-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting coloredlogs (from multiqc)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting spectra>=0.0.10 (from multiqc)\n",
      "  Downloading spectra-0.0.11.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pydantic>=2.7.0 (from multiqc)\n",
      "  Downloading pydantic-2.10.1-py3-none-any.whl.metadata (169 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.7/169.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting typeguard (from multiqc)\n",
      "  Downloading typeguard-4.4.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: tqdm in /home/auser/anaconda3/lib/python3.12/site-packages (from multiqc) (4.66.4)\n",
      "Collecting natsort (from multiqc)\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/auser/anaconda3/lib/python3.12/site-packages (from jinja2>=3.0.0->multiqc) (3.0.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/auser/anaconda3/lib/python3.12/site-packages (from plotly>=5.18->multiqc) (8.2.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/auser/anaconda3/lib/python3.12/site-packages (from pydantic>=2.7.0->multiqc) (0.6.0)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic>=2.7.0->multiqc)\n",
      "  Downloading pydantic_core-2.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic>=2.7.0->multiqc)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/auser/anaconda3/lib/python3.12/site-packages (from rich>=10->multiqc) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/auser/anaconda3/lib/python3.12/site-packages (from rich>=10->multiqc) (2.18.0)\n",
      "Collecting colormath>=3.0.0 (from spectra>=0.0.10->multiqc)\n",
      "  Downloading colormath-3.0.0.tar.gz (39 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->multiqc)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/auser/anaconda3/lib/python3.12/site-packages (from importlib-metadata->multiqc) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/auser/anaconda3/lib/python3.12/site-packages (from requests->multiqc) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/auser/anaconda3/lib/python3.12/site-packages (from requests->multiqc) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/auser/anaconda3/lib/python3.12/site-packages (from requests->multiqc) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/auser/anaconda3/lib/python3.12/site-packages (from requests->multiqc) (2024.8.30)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/auser/anaconda3/lib/python3.12/site-packages (from colormath>=3.0.0->spectra>=0.0.10->multiqc) (3.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/auser/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10->multiqc) (0.1.0)\n",
      "Downloading multiqc-1.25.2-py3-none-any.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pydantic-2.10.1-py3-none-any.whl (455 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.3/455.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanize-4.11.0-py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.1/128.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading rich_click-1.8.4-py3-none-any.whl (35 kB)\n",
      "Downloading typeguard-4.4.1-py3-none-any.whl (35 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Building wheels for collected packages: spectra, colormath\n",
      "  Building wheel for spectra (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for spectra: filename=spectra-0.0.11-py3-none-any.whl size=17466 sha256=7cac8e140f731d46b5b49d7f0eb145bd7e61de82b6c0973c55643780d4dc4d45\n",
      "  Stored in directory: /home/auser/.cache/pip/wheels/58/4a/f0/a641440e7d0b868ff5bcc8e1e17ad111ff7623976c5ee58d0a\n",
      "  Building wheel for colormath (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for colormath: filename=colormath-3.0.0-py3-none-any.whl size=39404 sha256=fd6c4d74fbafb4289612fc59e4229582f6cc5d12c8b79dcaee2beb3ffdf9e547\n",
      "  Stored in directory: /home/auser/.cache/pip/wheels/9a/32/6a/605739a172d8112031c9875d744aef91709f00de9b3bbb9274\n",
      "Successfully built spectra colormath\n",
      "Installing collected packages: kaleido, typing-extensions, natsort, humanize, humanfriendly, colormath, typeguard, spectra, pydantic-core, coloredlogs, rich-click, pydantic, multiqc\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.6\n",
      "    Uninstalling pydantic_core-2.14.6:\n",
      "      Successfully uninstalled pydantic_core-2.14.6\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.3\n",
      "    Uninstalling pydantic-2.5.3:\n",
      "      Successfully uninstalled pydantic-2.5.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.32.0 requires packaging<24,>=16.8, but you have packaging 24.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed coloredlogs-15.0.1 colormath-3.0.0 humanfriendly-10.0 humanize-4.11.0 kaleido-0.2.1 multiqc-1.25.2 natsort-8.4.0 pydantic-2.10.1 pydantic-core-2.27.1 rich-click-1.8.4 spectra-0.0.11 typeguard-4.4.1 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install multiqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C7frlKVnN7fn",
    "outputId": "208174b7-625a-40a3-f524-e813c5ff6430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[91m///\u001b[0m \u001b]8;id=238736;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\ 🔍 \u001b[2mv1.25.2\u001b[0m\n",
      "\n",
      "\u001b[34m       file_search\u001b[0m | Search path: /home/auser/dz4_1\n",
      "\u001b[2K         \u001b[34msearching\u001b[0m | \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m288/288\u001b[0m  88\u001b[0m \u001b[2mSRR3414631_1_fastqc.html\u001b[0m\n",
      "\u001b[?25h\u001b[34m            fastqc\u001b[0m | Found 6 reports\n",
      "\u001b[34m     write_results\u001b[0m | Data        : concatenated_report_data\n",
      "\u001b[34m     write_results\u001b[0m | Report      : concatenated_report.html\n",
      "\u001b[34m           multiqc\u001b[0m | MultiQC complete\n"
     ]
    }
   ],
   "source": [
    "!multiqc . --filename concatenated_report.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "5RdEc8GGCqpm",
    "outputId": "a91ad6a7-cb0f-491b-f78a-c6adaf58f0c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP file created at: concatenated_report_data.zip\n",
      "HTML file can be found at: concatenated_report.html\n",
      "To transfer the files, you can move them to a shared directory or use tools like scp to download to your local machine.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "source_dir = 'concatenated_report_data'  # Replace with the full path to your directory\n",
    "zip_file_path = 'concatenated_report_data.zip'  # Specify where to save the zip\n",
    "html_file_path = 'concatenated_report.html'  # Replace this with the HTML file's location\n",
    "\n",
    "# Create a zip of the directory\n",
    "with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            zipf.write(file_path, os.path.relpath(file_path, source_dir))\n",
    "\n",
    "print(f\"ZIP file created at: {zip_file_path}\")\n",
    "print(f\"HTML file can be found at: {html_file_path}\")\n",
    "\n",
    "# Inform the user to manually download the generated files\n",
    "print(\"To transfer the files, you can move them to a shared directory or use tools like scp to download to your local machine.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNDr03HyJNp6"
   },
   "source": [
    "**SRR3414635**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b23N89JW4Eeg"
   },
   "source": [
    "* Запускаем HISAT2 и картируем все чтения на геном мыши.\n",
    "* **Для одного образца программа работает 10-15 мин**\n",
    "* Общее кол-во чтений, и кол-во, которое удалось успешно откартировать (уникально и не уникально), указано в файле SRR34146__.hisat. Приводим эту информацию в отчете на Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "us6WSL8Ge6U_",
    "outputId": "c7f6b5cf-ec47-4325-8799-766d383f3c14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t4m39.456s\n",
      "user\t11m26.275s\n",
      "sys\t1m51.470s\n",
      "20956475 reads; of these:\n",
      "  20956475 (100.00%) were unpaired; of these:\n",
      "    242044 (1.15%) aligned 0 times\n",
      "    18637053 (88.93%) aligned exactly 1 time\n",
      "    2077378 (9.91%) aligned >1 times\n",
      "98.85% overall alignment rate\n"
     ]
    }
   ],
   "source": [
    "!time hisat2 -p 3 -x mm10/genome -U SRR3414635_1.fastq -S SRR3414635_1.sam  2>  SRR3414635.hisat\n",
    "!cat SRR3414635.hisat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7NUQXYU8C3w"
   },
   "source": [
    "* Отбираем только те чтения, которые откартировались уникально (флаг NH:i:1)\n",
    "* Удаляем исходные .sam файлы, т.к. они нам больше не потребуются\n",
    "* Считаем кол-во уникально-картированных чтений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0scVvWyz8Gjk",
    "outputId": "23cad1b3-5567-4fd7-c45e-208b6b1bc5e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'SRR3414635_1.sam'\n",
      "18637053\n"
     ]
    }
   ],
   "source": [
    "!grep -P '^@|NH:i:1$' SRR3414635_1.sam > SRR3414635.uniq.sam\n",
    "!rm -v SRR3414635_1.sam\n",
    "!grep -v '^@' SRR3414635.uniq.sam | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3F_9bkiIEP2"
   },
   "source": [
    "**SRR3414636**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zmWhI1UIHnq",
    "outputId": "6da8d4dd-ac29-48a1-e53d-76ff2150e4d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t5m31.046s\n",
      "user\t10m44.223s\n",
      "sys\t2m51.103s\n",
      "20307147 reads; of these:\n",
      "  20307147 (100.00%) were unpaired; of these:\n",
      "    233551 (1.15%) aligned 0 times\n",
      "    18032679 (88.80%) aligned exactly 1 time\n",
      "    2040917 (10.05%) aligned >1 times\n",
      "98.85% overall alignment rate\n"
     ]
    }
   ],
   "source": [
    "!time hisat2 -p 3 -x mm10/genome -U SRR3414636_1.fastq -S SRR3414636_1.sam  2>  SRR3414636.hisat\n",
    "!cat SRR3414636.hisat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSk9QiZFIMC-",
    "outputId": "54a2a8c7-8539-43cf-ca0e-d771b4049826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'SRR3414636_1.sam'\n",
      "18032679\n"
     ]
    }
   ],
   "source": [
    "!grep -P '^@|NH:i:1$' SRR3414636_1.sam > SRR3414636.uniq.sam\n",
    "!rm -v SRR3414636_1.sam\n",
    "!grep -v '^@' SRR3414636.uniq.sam | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOVEtiaxIWus"
   },
   "source": [
    "**SRR3414637**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZQ1vE78vIbN1",
    "outputId": "2c0612e7-e5e1-4124-dd9f-9d3959ea8c32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t5m37.828s\n",
      "user\t11m31.406s\n",
      "sys\t2m6.217s\n",
      "20385570 reads; of these:\n",
      "  20385570 (100.00%) were unpaired; of these:\n",
      "    236895 (1.16%) aligned 0 times\n",
      "    18043406 (88.51%) aligned exactly 1 time\n",
      "    2105269 (10.33%) aligned >1 times\n",
      "98.84% overall alignment rate\n"
     ]
    }
   ],
   "source": [
    "!time hisat2 -p 3 -x mm10/genome -U SRR3414637_1.fastq -S SRR3414637_1.sam  2>  SRR3414637.hisat\n",
    "!cat SRR3414637.hisat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZuLIKwMMIggS",
    "outputId": "d67f15d2-e53b-4ae9-dbd2-2374f77372ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'SRR3414637_1.sam'\n",
      "18043406\n"
     ]
    }
   ],
   "source": [
    "!grep -P '^@|NH:i:1$' SRR3414637_1.sam > SRR3414637.uniq.sam\n",
    "!rm -v SRR3414637_1.sam\n",
    "!grep -v '^@' SRR3414637.uniq.sam | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdxWQ97WIlSD"
   },
   "source": [
    "**SRR3414629**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQhFF-lRIr9a",
    "outputId": "97bf2dc4-36a9-4dca-d90e-9a5b19d29876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t5m18.486s\n",
      "user\t11m56.639s\n",
      "sys\t2m43.796s\n",
      "21106089 reads; of these:\n",
      "  21106089 (100.00%) were unpaired; of these:\n",
      "    241118 (1.14%) aligned 0 times\n",
      "    18573565 (88.00%) aligned exactly 1 time\n",
      "    2291406 (10.86%) aligned >1 times\n",
      "98.86% overall alignment rate\n"
     ]
    }
   ],
   "source": [
    "!time hisat2 -p 3 -x mm10/genome -U SRR3414629_1.fastq -S SRR3414629_1.sam  2>  SRR3414629.hisat\n",
    "!cat SRR3414629.hisat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5BYEW90UIv_G",
    "outputId": "98a0574f-bd55-4e19-b148-5d9192196958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'SRR3414629_1.sam'\n",
      "18573565\n"
     ]
    }
   ],
   "source": [
    "!grep -P '^@|NH:i:1$' SRR3414629_1.sam > SRR3414629.uniq.sam\n",
    "!rm -v SRR3414629_1.sam\n",
    "!grep -v '^@' SRR3414629.uniq.sam | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMKfF_cNIzO7"
   },
   "source": [
    "**SRR3414630**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZsBkGuFI3Uw",
    "outputId": "f6df296b-ee3d-446f-e62c-bb03746bc77d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t3m58.062s\n",
      "user\t8m32.423s\n",
      "sys\t1m43.928s\n",
      "15244711 reads; of these:\n",
      "  15244711 (100.00%) were unpaired; of these:\n",
      "    168274 (1.10%) aligned 0 times\n",
      "    13320505 (87.38%) aligned exactly 1 time\n",
      "    1755932 (11.52%) aligned >1 times\n",
      "98.90% overall alignment rate\n"
     ]
    }
   ],
   "source": [
    "!time hisat2 -p 3 -x mm10/genome -U SRR3414630_1.fastq -S SRR3414630_1.sam  2>  SRR3414630.hisat\n",
    "!cat SRR3414630.hisat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GxNnMIckI7PU",
    "outputId": "306cec15-68c7-423b-c714-5178b8b8a826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'SRR3414630_1.sam'\n",
      "13320505\n"
     ]
    }
   ],
   "source": [
    "!grep -P '^@|NH:i:1$' SRR3414630_1.sam > SRR3414630.uniq.sam\n",
    "!rm -v SRR3414630_1.sam\n",
    "!grep -v '^@' SRR3414630.uniq.sam | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nstQqfIZJBWQ"
   },
   "source": [
    "**SRR3414631**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szNimWGLJCjP",
    "outputId": "e979f7b6-0393-4460-c5f8-1c7fbb652299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t6m21.618s\n",
      "user\t13m59.017s\n",
      "sys\t2m56.449s\n",
      "24244069 reads; of these:\n",
      "  24244069 (100.00%) were unpaired; of these:\n",
      "    279694 (1.15%) aligned 0 times\n",
      "    21159606 (87.28%) aligned exactly 1 time\n",
      "    2804769 (11.57%) aligned >1 times\n",
      "98.85% overall alignment rate\n"
     ]
    }
   ],
   "source": [
    "!time hisat2 -p 3 -x mm10/genome -U SRR3414631_1.fastq -S SRR3414631_1.sam  2>  SRR3414631.hisat\n",
    "!cat SRR3414631.hisat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vsvyz0PYJFz5",
    "outputId": "d7574dbc-923e-40b4-8317-6b99fdc14161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'SRR3414631_1.sam'\n",
      "21159606\n"
     ]
    }
   ],
   "source": [
    "!grep -P '^@|NH:i:1$' SRR3414631_1.sam > SRR3414631.uniq.sam\n",
    "!rm -v SRR3414631_1.sam\n",
    "!grep -v '^@' SRR3414631.uniq.sam | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9UlR8HTp6jF"
   },
   "source": [
    "Удаляем ненужные файлы, чтобы очистить память"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lww5MZloJlrT",
    "outputId": "3eeab58e-34a4-498c-a11b-e5072b37c4e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'SRR3414635_1.fastq'\n",
      "removed 'SRR3414636_1.fastq'\n",
      "removed 'SRR3414637_1.fastq'\n",
      "removed 'SRR3414629_1.fastq'\n",
      "removed 'SRR3414630_1.fastq'\n",
      "removed 'SRR3414631_1.fastq'\n"
     ]
    }
   ],
   "source": [
    "!rm -v SRR3414635_1.fastq\n",
    "!rm -v SRR3414636_1.fastq\n",
    "!rm -v SRR3414637_1.fastq\n",
    "!rm -v SRR3414629_1.fastq\n",
    "!rm -v SRR3414630_1.fastq\n",
    "!rm -v SRR3414631_1.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kfa9VdqyXAi9",
    "outputId": "db7f9fff-f619-44de-a39a-3db6061572f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'SRR3414635.hisat'\n",
      "removed 'SRR3414636.hisat'\n",
      "removed 'SRR3414637.hisat'\n",
      "removed 'SRR3414629.hisat'\n",
      "removed 'SRR3414630.hisat'\n",
      "removed 'SRR3414631.hisat'\n"
     ]
    }
   ],
   "source": [
    "!rm -v SRR3414635.hisat\n",
    "!rm -v SRR3414636.hisat\n",
    "!rm -v SRR3414637.hisat\n",
    "!rm -v SRR3414629.hisat\n",
    "!rm -v SRR3414630.hisat\n",
    "!rm -v SRR3414631.hisat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JqUV4J_8a8h"
   },
   "source": [
    "* С помощью программы `HTSeq` Подсчитываем количество чтений, попавших на каждый ген (**для одного образца программа работает 15-20 мин**):\n",
    "* Аннтоация генома мыши в формате .gtf находится в файле `gencode.vM25.annotation.gtf`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7IHTD5Ihorm",
    "outputId": "6e0a5b05-c04c-4c5f-eb69-9a161c1424fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1872052 GFF lines processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "400000 alignment records processed.\n",
      "500000 alignment records processed.\n",
      "600000 alignment records processed.\n",
      "700000 alignment records processed.\n",
      "800000 alignment records processed.\n",
      "900000 alignment records processed.\n",
      "1000000 alignment records processed.\n",
      "1100000 alignment records processed.\n",
      "1200000 alignment records processed.\n",
      "1300000 alignment records processed.\n",
      "1400000 alignment records processed.\n",
      "1500000 alignment records processed.\n",
      "1600000 alignment records processed.\n",
      "1700000 alignment records processed.\n",
      "1800000 alignment records processed.\n",
      "1900000 alignment records processed.\n",
      "2000000 alignment records processed.\n",
      "2100000 alignment records processed.\n",
      "2200000 alignment records processed.\n",
      "2300000 alignment records processed.\n",
      "2400000 alignment records processed.\n",
      "2500000 alignment records processed.\n",
      "2600000 alignment records processed.\n",
      "2700000 alignment records processed.\n",
      "2800000 alignment records processed.\n",
      "2900000 alignment records processed.\n",
      "3000000 alignment records processed.\n",
      "3100000 alignment records processed.\n",
      "3200000 alignment records processed.\n",
      "3300000 alignment records processed.\n",
      "3400000 alignment records processed.\n",
      "3500000 alignment records processed.\n",
      "3600000 alignment records processed.\n",
      "3700000 alignment records processed.\n",
      "3800000 alignment records processed.\n",
      "3900000 alignment records processed.\n",
      "4000000 alignment records processed.\n",
      "4100000 alignment records processed.\n",
      "4200000 alignment records processed.\n",
      "4300000 alignment records processed.\n",
      "4400000 alignment records processed.\n",
      "4500000 alignment records processed.\n",
      "4600000 alignment records processed.\n",
      "4700000 alignment records processed.\n",
      "4800000 alignment records processed.\n",
      "4900000 alignment records processed.\n",
      "5000000 alignment records processed.\n",
      "5100000 alignment records processed.\n",
      "5200000 alignment records processed.\n",
      "5300000 alignment records processed.\n",
      "5400000 alignment records processed.\n",
      "5500000 alignment records processed.\n",
      "5600000 alignment records processed.\n",
      "5700000 alignment records processed.\n",
      "5800000 alignment records processed.\n",
      "5900000 alignment records processed.\n",
      "6000000 alignment records processed.\n",
      "6100000 alignment records processed.\n",
      "6200000 alignment records processed.\n",
      "6300000 alignment records processed.\n",
      "6400000 alignment records processed.\n",
      "6500000 alignment records processed.\n",
      "6600000 alignment records processed.\n",
      "6700000 alignment records processed.\n",
      "6800000 alignment records processed.\n",
      "6900000 alignment records processed.\n",
      "7000000 alignment records processed.\n",
      "7100000 alignment records processed.\n",
      "7200000 alignment records processed.\n",
      "7300000 alignment records processed.\n",
      "7400000 alignment records processed.\n",
      "7500000 alignment records processed.\n",
      "7600000 alignment records processed.\n",
      "7700000 alignment records processed.\n",
      "7800000 alignment records processed.\n",
      "7900000 alignment records processed.\n",
      "8000000 alignment records processed.\n",
      "8100000 alignment records processed.\n",
      "8200000 alignment records processed.\n",
      "8300000 alignment records processed.\n",
      "8400000 alignment records processed.\n",
      "8500000 alignment records processed.\n",
      "8600000 alignment records processed.\n",
      "8700000 alignment records processed.\n",
      "8800000 alignment records processed.\n",
      "8900000 alignment records processed.\n",
      "9000000 alignment records processed.\n",
      "9100000 alignment records processed.\n",
      "9200000 alignment records processed.\n",
      "9300000 alignment records processed.\n",
      "9400000 alignment records processed.\n",
      "9500000 alignment records processed.\n",
      "9600000 alignment records processed.\n",
      "9700000 alignment records processed.\n",
      "9800000 alignment records processed.\n",
      "9900000 alignment records processed.\n",
      "10000000 alignment records processed.\n",
      "10100000 alignment records processed.\n",
      "10200000 alignment records processed.\n",
      "10300000 alignment records processed.\n",
      "10400000 alignment records processed.\n",
      "10500000 alignment records processed.\n",
      "10600000 alignment records processed.\n",
      "10700000 alignment records processed.\n",
      "10800000 alignment records processed.\n",
      "10900000 alignment records processed.\n",
      "11000000 alignment records processed.\n",
      "11100000 alignment records processed.\n",
      "11200000 alignment records processed.\n",
      "11300000 alignment records processed.\n",
      "11400000 alignment records processed.\n",
      "11500000 alignment records processed.\n",
      "11600000 alignment records processed.\n",
      "11700000 alignment records processed.\n",
      "11800000 alignment records processed.\n",
      "11900000 alignment records processed.\n",
      "12000000 alignment records processed.\n",
      "12100000 alignment records processed.\n",
      "12200000 alignment records processed.\n",
      "12300000 alignment records processed.\n",
      "12400000 alignment records processed.\n",
      "12500000 alignment records processed.\n",
      "12600000 alignment records processed.\n",
      "12700000 alignment records processed.\n",
      "12800000 alignment records processed.\n",
      "12900000 alignment records processed.\n",
      "13000000 alignment records processed.\n",
      "13100000 alignment records processed.\n",
      "13200000 alignment records processed.\n",
      "13300000 alignment records processed.\n",
      "13400000 alignment records processed.\n",
      "13500000 alignment records processed.\n",
      "13600000 alignment records processed.\n",
      "13700000 alignment records processed.\n",
      "13800000 alignment records processed.\n",
      "13900000 alignment records processed.\n",
      "14000000 alignment records processed.\n",
      "14100000 alignment records processed.\n",
      "14200000 alignment records processed.\n",
      "14300000 alignment records processed.\n",
      "14400000 alignment records processed.\n",
      "14500000 alignment records processed.\n",
      "14600000 alignment records processed.\n",
      "14700000 alignment records processed.\n",
      "14800000 alignment records processed.\n",
      "14900000 alignment records processed.\n",
      "15000000 alignment records processed.\n",
      "15100000 alignment records processed.\n",
      "15200000 alignment records processed.\n",
      "15300000 alignment records processed.\n",
      "15400000 alignment records processed.\n",
      "15500000 alignment records processed.\n",
      "15600000 alignment records processed.\n",
      "15700000 alignment records processed.\n",
      "15800000 alignment records processed.\n",
      "15900000 alignment records processed.\n",
      "16000000 alignment records processed.\n",
      "16100000 alignment records processed.\n",
      "16200000 alignment records processed.\n",
      "16300000 alignment records processed.\n",
      "16400000 alignment records processed.\n",
      "16500000 alignment records processed.\n",
      "16600000 alignment records processed.\n",
      "16700000 alignment records processed.\n",
      "16800000 alignment records processed.\n",
      "16900000 alignment records processed.\n",
      "17000000 alignment records processed.\n",
      "17100000 alignment records processed.\n",
      "17200000 alignment records processed.\n",
      "17300000 alignment records processed.\n",
      "17400000 alignment records processed.\n",
      "17500000 alignment records processed.\n",
      "17600000 alignment records processed.\n",
      "17700000 alignment records processed.\n",
      "17800000 alignment records processed.\n",
      "17900000 alignment records processed.\n",
      "18000000 alignment records processed.\n",
      "18100000 alignment records processed.\n",
      "18200000 alignment records processed.\n",
      "18300000 alignment records processed.\n",
      "18400000 alignment records processed.\n",
      "18500000 alignment records processed.\n",
      "18600000 alignment records processed.\n",
      "18637053 alignment records processed.\n",
      "\n",
      "real\t10m43.013s\n",
      "user\t10m33.142s\n",
      "sys\t0m5.581s\n",
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1872052 GFF lines processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "400000 alignment records processed.\n",
      "500000 alignment records processed.\n",
      "600000 alignment records processed.\n",
      "700000 alignment records processed.\n",
      "800000 alignment records processed.\n",
      "900000 alignment records processed.\n",
      "1000000 alignment records processed.\n",
      "1100000 alignment records processed.\n",
      "1200000 alignment records processed.\n",
      "1300000 alignment records processed.\n",
      "1400000 alignment records processed.\n",
      "1500000 alignment records processed.\n",
      "1600000 alignment records processed.\n",
      "1700000 alignment records processed.\n",
      "1800000 alignment records processed.\n",
      "1900000 alignment records processed.\n",
      "2000000 alignment records processed.\n",
      "2100000 alignment records processed.\n",
      "2200000 alignment records processed.\n",
      "2300000 alignment records processed.\n",
      "2400000 alignment records processed.\n",
      "2500000 alignment records processed.\n",
      "2600000 alignment records processed.\n",
      "2700000 alignment records processed.\n",
      "2800000 alignment records processed.\n",
      "2900000 alignment records processed.\n",
      "3000000 alignment records processed.\n",
      "3100000 alignment records processed.\n",
      "3200000 alignment records processed.\n",
      "3300000 alignment records processed.\n",
      "3400000 alignment records processed.\n",
      "3500000 alignment records processed.\n",
      "3600000 alignment records processed.\n",
      "3700000 alignment records processed.\n",
      "3800000 alignment records processed.\n",
      "3900000 alignment records processed.\n",
      "4000000 alignment records processed.\n",
      "4100000 alignment records processed.\n",
      "4200000 alignment records processed.\n",
      "4300000 alignment records processed.\n",
      "4400000 alignment records processed.\n",
      "4500000 alignment records processed.\n",
      "4600000 alignment records processed.\n",
      "4700000 alignment records processed.\n",
      "4800000 alignment records processed.\n",
      "4900000 alignment records processed.\n",
      "5000000 alignment records processed.\n",
      "5100000 alignment records processed.\n",
      "5200000 alignment records processed.\n",
      "5300000 alignment records processed.\n",
      "5400000 alignment records processed.\n",
      "5500000 alignment records processed.\n",
      "5600000 alignment records processed.\n",
      "5700000 alignment records processed.\n",
      "5800000 alignment records processed.\n",
      "5900000 alignment records processed.\n",
      "6000000 alignment records processed.\n",
      "6100000 alignment records processed.\n",
      "6200000 alignment records processed.\n",
      "6300000 alignment records processed.\n",
      "6400000 alignment records processed.\n",
      "6500000 alignment records processed.\n",
      "6600000 alignment records processed.\n",
      "6700000 alignment records processed.\n",
      "6800000 alignment records processed.\n",
      "6900000 alignment records processed.\n",
      "7000000 alignment records processed.\n",
      "7100000 alignment records processed.\n",
      "7200000 alignment records processed.\n",
      "7300000 alignment records processed.\n",
      "7400000 alignment records processed.\n",
      "7500000 alignment records processed.\n",
      "7600000 alignment records processed.\n",
      "7700000 alignment records processed.\n",
      "7800000 alignment records processed.\n",
      "7900000 alignment records processed.\n",
      "8000000 alignment records processed.\n",
      "8100000 alignment records processed.\n",
      "8200000 alignment records processed.\n",
      "8300000 alignment records processed.\n",
      "8400000 alignment records processed.\n",
      "8500000 alignment records processed.\n",
      "8600000 alignment records processed.\n",
      "8700000 alignment records processed.\n",
      "8800000 alignment records processed.\n",
      "8900000 alignment records processed.\n",
      "9000000 alignment records processed.\n",
      "9100000 alignment records processed.\n",
      "9200000 alignment records processed.\n",
      "9300000 alignment records processed.\n",
      "9400000 alignment records processed.\n",
      "9500000 alignment records processed.\n",
      "9600000 alignment records processed.\n",
      "9700000 alignment records processed.\n",
      "9800000 alignment records processed.\n",
      "9900000 alignment records processed.\n",
      "10000000 alignment records processed.\n",
      "10100000 alignment records processed.\n",
      "10200000 alignment records processed.\n",
      "10300000 alignment records processed.\n",
      "10400000 alignment records processed.\n",
      "10500000 alignment records processed.\n",
      "10600000 alignment records processed.\n",
      "10700000 alignment records processed.\n",
      "10800000 alignment records processed.\n",
      "10900000 alignment records processed.\n",
      "11000000 alignment records processed.\n",
      "11100000 alignment records processed.\n",
      "11200000 alignment records processed.\n",
      "11300000 alignment records processed.\n",
      "11400000 alignment records processed.\n",
      "11500000 alignment records processed.\n",
      "11600000 alignment records processed.\n",
      "11700000 alignment records processed.\n",
      "11800000 alignment records processed.\n",
      "11900000 alignment records processed.\n",
      "12000000 alignment records processed.\n",
      "12100000 alignment records processed.\n",
      "12200000 alignment records processed.\n",
      "12300000 alignment records processed.\n",
      "12400000 alignment records processed.\n",
      "12500000 alignment records processed.\n",
      "12600000 alignment records processed.\n",
      "12700000 alignment records processed.\n",
      "12800000 alignment records processed.\n",
      "12900000 alignment records processed.\n",
      "13000000 alignment records processed.\n",
      "13100000 alignment records processed.\n",
      "13200000 alignment records processed.\n",
      "13300000 alignment records processed.\n",
      "13400000 alignment records processed.\n",
      "13500000 alignment records processed.\n",
      "13600000 alignment records processed.\n",
      "13700000 alignment records processed.\n",
      "13800000 alignment records processed.\n",
      "13900000 alignment records processed.\n",
      "14000000 alignment records processed.\n",
      "14100000 alignment records processed.\n",
      "14200000 alignment records processed.\n",
      "14300000 alignment records processed.\n",
      "14400000 alignment records processed.\n",
      "14500000 alignment records processed.\n",
      "14600000 alignment records processed.\n",
      "14700000 alignment records processed.\n",
      "14800000 alignment records processed.\n",
      "14900000 alignment records processed.\n",
      "15000000 alignment records processed.\n",
      "15100000 alignment records processed.\n",
      "15200000 alignment records processed.\n",
      "15300000 alignment records processed.\n",
      "15400000 alignment records processed.\n",
      "15500000 alignment records processed.\n",
      "15600000 alignment records processed.\n",
      "15700000 alignment records processed.\n",
      "15800000 alignment records processed.\n",
      "15900000 alignment records processed.\n",
      "16000000 alignment records processed.\n",
      "16100000 alignment records processed.\n",
      "16200000 alignment records processed.\n",
      "16300000 alignment records processed.\n",
      "16400000 alignment records processed.\n",
      "16500000 alignment records processed.\n",
      "16600000 alignment records processed.\n",
      "16700000 alignment records processed.\n",
      "16800000 alignment records processed.\n",
      "16900000 alignment records processed.\n",
      "17000000 alignment records processed.\n",
      "17100000 alignment records processed.\n",
      "17200000 alignment records processed.\n",
      "17300000 alignment records processed.\n",
      "17400000 alignment records processed.\n",
      "17500000 alignment records processed.\n",
      "17600000 alignment records processed.\n",
      "17700000 alignment records processed.\n",
      "17800000 alignment records processed.\n",
      "17900000 alignment records processed.\n",
      "18000000 alignment records processed.\n",
      "18032679 alignment records processed.\n",
      "\n",
      "real\t10m25.727s\n",
      "user\t10m20.485s\n",
      "sys\t0m5.190s\n",
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1872052 GFF lines processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "400000 alignment records processed.\n",
      "500000 alignment records processed.\n",
      "600000 alignment records processed.\n",
      "700000 alignment records processed.\n",
      "800000 alignment records processed.\n",
      "900000 alignment records processed.\n",
      "1000000 alignment records processed.\n",
      "1100000 alignment records processed.\n",
      "1200000 alignment records processed.\n",
      "1300000 alignment records processed.\n",
      "1400000 alignment records processed.\n",
      "1500000 alignment records processed.\n",
      "1600000 alignment records processed.\n",
      "1700000 alignment records processed.\n",
      "1800000 alignment records processed.\n",
      "1900000 alignment records processed.\n",
      "2000000 alignment records processed.\n",
      "2100000 alignment records processed.\n",
      "2200000 alignment records processed.\n",
      "2300000 alignment records processed.\n",
      "2400000 alignment records processed.\n",
      "2500000 alignment records processed.\n",
      "2600000 alignment records processed.\n",
      "2700000 alignment records processed.\n",
      "2800000 alignment records processed.\n",
      "2900000 alignment records processed.\n",
      "3000000 alignment records processed.\n",
      "3100000 alignment records processed.\n",
      "3200000 alignment records processed.\n",
      "3300000 alignment records processed.\n",
      "3400000 alignment records processed.\n",
      "3500000 alignment records processed.\n",
      "3600000 alignment records processed.\n",
      "3700000 alignment records processed.\n",
      "3800000 alignment records processed.\n",
      "3900000 alignment records processed.\n",
      "4000000 alignment records processed.\n",
      "4100000 alignment records processed.\n",
      "4200000 alignment records processed.\n",
      "4300000 alignment records processed.\n",
      "4400000 alignment records processed.\n",
      "4500000 alignment records processed.\n",
      "4600000 alignment records processed.\n",
      "4700000 alignment records processed.\n",
      "4800000 alignment records processed.\n",
      "4900000 alignment records processed.\n",
      "5000000 alignment records processed.\n",
      "5100000 alignment records processed.\n",
      "5200000 alignment records processed.\n",
      "5300000 alignment records processed.\n",
      "5400000 alignment records processed.\n",
      "5500000 alignment records processed.\n",
      "5600000 alignment records processed.\n",
      "5700000 alignment records processed.\n",
      "5800000 alignment records processed.\n",
      "5900000 alignment records processed.\n",
      "6000000 alignment records processed.\n",
      "6100000 alignment records processed.\n",
      "6200000 alignment records processed.\n",
      "6300000 alignment records processed.\n",
      "6400000 alignment records processed.\n",
      "6500000 alignment records processed.\n",
      "6600000 alignment records processed.\n",
      "6700000 alignment records processed.\n",
      "6800000 alignment records processed.\n",
      "6900000 alignment records processed.\n",
      "7000000 alignment records processed.\n",
      "7100000 alignment records processed.\n",
      "7200000 alignment records processed.\n",
      "7300000 alignment records processed.\n",
      "7400000 alignment records processed.\n",
      "7500000 alignment records processed.\n",
      "7600000 alignment records processed.\n",
      "7700000 alignment records processed.\n",
      "7800000 alignment records processed.\n",
      "7900000 alignment records processed.\n",
      "8000000 alignment records processed.\n",
      "8100000 alignment records processed.\n",
      "8200000 alignment records processed.\n",
      "8300000 alignment records processed.\n",
      "8400000 alignment records processed.\n",
      "8500000 alignment records processed.\n",
      "8600000 alignment records processed.\n",
      "8700000 alignment records processed.\n",
      "8800000 alignment records processed.\n",
      "8900000 alignment records processed.\n",
      "9000000 alignment records processed.\n",
      "9100000 alignment records processed.\n",
      "9200000 alignment records processed.\n",
      "9300000 alignment records processed.\n",
      "9400000 alignment records processed.\n",
      "9500000 alignment records processed.\n",
      "9600000 alignment records processed.\n",
      "9700000 alignment records processed.\n",
      "9800000 alignment records processed.\n",
      "9900000 alignment records processed.\n",
      "10000000 alignment records processed.\n",
      "10100000 alignment records processed.\n",
      "10200000 alignment records processed.\n",
      "10300000 alignment records processed.\n",
      "10400000 alignment records processed.\n",
      "10500000 alignment records processed.\n",
      "10600000 alignment records processed.\n",
      "10700000 alignment records processed.\n",
      "10800000 alignment records processed.\n",
      "10900000 alignment records processed.\n",
      "11000000 alignment records processed.\n",
      "11100000 alignment records processed.\n",
      "11200000 alignment records processed.\n",
      "11300000 alignment records processed.\n",
      "11400000 alignment records processed.\n",
      "11500000 alignment records processed.\n",
      "11600000 alignment records processed.\n",
      "11700000 alignment records processed.\n",
      "11800000 alignment records processed.\n",
      "11900000 alignment records processed.\n",
      "12000000 alignment records processed.\n",
      "12100000 alignment records processed.\n",
      "12200000 alignment records processed.\n",
      "12300000 alignment records processed.\n",
      "12400000 alignment records processed.\n",
      "12500000 alignment records processed.\n",
      "12600000 alignment records processed.\n",
      "12700000 alignment records processed.\n",
      "12800000 alignment records processed.\n",
      "12900000 alignment records processed.\n",
      "13000000 alignment records processed.\n",
      "13100000 alignment records processed.\n",
      "13200000 alignment records processed.\n",
      "13300000 alignment records processed.\n",
      "13400000 alignment records processed.\n",
      "13500000 alignment records processed.\n",
      "13600000 alignment records processed.\n",
      "13700000 alignment records processed.\n",
      "13800000 alignment records processed.\n",
      "13900000 alignment records processed.\n",
      "14000000 alignment records processed.\n",
      "14100000 alignment records processed.\n",
      "14200000 alignment records processed.\n",
      "14300000 alignment records processed.\n",
      "14400000 alignment records processed.\n",
      "14500000 alignment records processed.\n",
      "14600000 alignment records processed.\n",
      "14700000 alignment records processed.\n",
      "14800000 alignment records processed.\n",
      "14900000 alignment records processed.\n",
      "15000000 alignment records processed.\n",
      "15100000 alignment records processed.\n",
      "15200000 alignment records processed.\n",
      "15300000 alignment records processed.\n",
      "15400000 alignment records processed.\n",
      "15500000 alignment records processed.\n",
      "15600000 alignment records processed.\n",
      "15700000 alignment records processed.\n",
      "15800000 alignment records processed.\n",
      "15900000 alignment records processed.\n",
      "16000000 alignment records processed.\n",
      "16100000 alignment records processed.\n",
      "16200000 alignment records processed.\n",
      "16300000 alignment records processed.\n",
      "16400000 alignment records processed.\n",
      "16500000 alignment records processed.\n",
      "16600000 alignment records processed.\n",
      "16700000 alignment records processed.\n",
      "16800000 alignment records processed.\n",
      "16900000 alignment records processed.\n",
      "17000000 alignment records processed.\n",
      "17100000 alignment records processed.\n",
      "17200000 alignment records processed.\n",
      "17300000 alignment records processed.\n",
      "17400000 alignment records processed.\n",
      "17500000 alignment records processed.\n",
      "17600000 alignment records processed.\n",
      "17700000 alignment records processed.\n",
      "17800000 alignment records processed.\n",
      "17900000 alignment records processed.\n",
      "18000000 alignment records processed.\n",
      "18043406 alignment records processed.\n",
      "\n",
      "real\t10m47.308s\n",
      "user\t10m40.751s\n",
      "sys\t0m6.540s\n",
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1872052 GFF lines processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "400000 alignment records processed.\n",
      "500000 alignment records processed.\n",
      "600000 alignment records processed.\n",
      "700000 alignment records processed.\n",
      "800000 alignment records processed.\n",
      "900000 alignment records processed.\n",
      "1000000 alignment records processed.\n",
      "1100000 alignment records processed.\n",
      "1200000 alignment records processed.\n",
      "1300000 alignment records processed.\n",
      "1400000 alignment records processed.\n",
      "1500000 alignment records processed.\n",
      "1600000 alignment records processed.\n",
      "1700000 alignment records processed.\n",
      "1800000 alignment records processed.\n",
      "1900000 alignment records processed.\n",
      "2000000 alignment records processed.\n",
      "2100000 alignment records processed.\n",
      "2200000 alignment records processed.\n",
      "2300000 alignment records processed.\n",
      "2400000 alignment records processed.\n",
      "2500000 alignment records processed.\n",
      "2600000 alignment records processed.\n",
      "2700000 alignment records processed.\n",
      "2800000 alignment records processed.\n",
      "2900000 alignment records processed.\n",
      "3000000 alignment records processed.\n",
      "3100000 alignment records processed.\n",
      "3200000 alignment records processed.\n",
      "3300000 alignment records processed.\n",
      "3400000 alignment records processed.\n",
      "3500000 alignment records processed.\n",
      "3600000 alignment records processed.\n",
      "3700000 alignment records processed.\n",
      "3800000 alignment records processed.\n",
      "3900000 alignment records processed.\n",
      "4000000 alignment records processed.\n",
      "4100000 alignment records processed.\n",
      "4200000 alignment records processed.\n",
      "4300000 alignment records processed.\n",
      "4400000 alignment records processed.\n",
      "4500000 alignment records processed.\n",
      "4600000 alignment records processed.\n",
      "4700000 alignment records processed.\n",
      "4800000 alignment records processed.\n",
      "4900000 alignment records processed.\n",
      "5000000 alignment records processed.\n",
      "5100000 alignment records processed.\n",
      "5200000 alignment records processed.\n",
      "5300000 alignment records processed.\n",
      "5400000 alignment records processed.\n",
      "5500000 alignment records processed.\n",
      "5600000 alignment records processed.\n",
      "5700000 alignment records processed.\n",
      "5800000 alignment records processed.\n",
      "5900000 alignment records processed.\n",
      "6000000 alignment records processed.\n",
      "6100000 alignment records processed.\n",
      "6200000 alignment records processed.\n",
      "6300000 alignment records processed.\n",
      "6400000 alignment records processed.\n",
      "6500000 alignment records processed.\n",
      "6600000 alignment records processed.\n",
      "6700000 alignment records processed.\n",
      "6800000 alignment records processed.\n",
      "6900000 alignment records processed.\n",
      "7000000 alignment records processed.\n",
      "7100000 alignment records processed.\n",
      "7200000 alignment records processed.\n",
      "7300000 alignment records processed.\n",
      "7400000 alignment records processed.\n",
      "7500000 alignment records processed.\n",
      "7600000 alignment records processed.\n",
      "7700000 alignment records processed.\n",
      "7800000 alignment records processed.\n",
      "7900000 alignment records processed.\n",
      "8000000 alignment records processed.\n",
      "8100000 alignment records processed.\n",
      "8200000 alignment records processed.\n",
      "8300000 alignment records processed.\n",
      "8400000 alignment records processed.\n",
      "8500000 alignment records processed.\n",
      "8600000 alignment records processed.\n",
      "8700000 alignment records processed.\n",
      "8800000 alignment records processed.\n",
      "8900000 alignment records processed.\n",
      "9000000 alignment records processed.\n",
      "9100000 alignment records processed.\n",
      "9200000 alignment records processed.\n",
      "9300000 alignment records processed.\n",
      "9400000 alignment records processed.\n",
      "9500000 alignment records processed.\n",
      "9600000 alignment records processed.\n",
      "9700000 alignment records processed.\n",
      "9800000 alignment records processed.\n",
      "9900000 alignment records processed.\n",
      "10000000 alignment records processed.\n",
      "10100000 alignment records processed.\n",
      "10200000 alignment records processed.\n",
      "10300000 alignment records processed.\n",
      "10400000 alignment records processed.\n",
      "10500000 alignment records processed.\n",
      "10600000 alignment records processed.\n",
      "10700000 alignment records processed.\n",
      "10800000 alignment records processed.\n",
      "10900000 alignment records processed.\n",
      "11000000 alignment records processed.\n",
      "11100000 alignment records processed.\n",
      "11200000 alignment records processed.\n",
      "11300000 alignment records processed.\n",
      "11400000 alignment records processed.\n",
      "11500000 alignment records processed.\n",
      "11600000 alignment records processed.\n",
      "11700000 alignment records processed.\n",
      "11800000 alignment records processed.\n",
      "11900000 alignment records processed.\n",
      "12000000 alignment records processed.\n",
      "12100000 alignment records processed.\n",
      "12200000 alignment records processed.\n",
      "12300000 alignment records processed.\n",
      "12400000 alignment records processed.\n",
      "12500000 alignment records processed.\n",
      "12600000 alignment records processed.\n",
      "12700000 alignment records processed.\n",
      "12800000 alignment records processed.\n",
      "12900000 alignment records processed.\n",
      "13000000 alignment records processed.\n",
      "13100000 alignment records processed.\n",
      "13200000 alignment records processed.\n",
      "13300000 alignment records processed.\n",
      "13400000 alignment records processed.\n",
      "13500000 alignment records processed.\n",
      "13600000 alignment records processed.\n",
      "13700000 alignment records processed.\n",
      "13800000 alignment records processed.\n",
      "13900000 alignment records processed.\n",
      "14000000 alignment records processed.\n",
      "14100000 alignment records processed.\n",
      "14200000 alignment records processed.\n",
      "14300000 alignment records processed.\n",
      "14400000 alignment records processed.\n",
      "14500000 alignment records processed.\n",
      "14600000 alignment records processed.\n",
      "14700000 alignment records processed.\n",
      "14800000 alignment records processed.\n",
      "14900000 alignment records processed.\n",
      "15000000 alignment records processed.\n",
      "15100000 alignment records processed.\n",
      "15200000 alignment records processed.\n",
      "15300000 alignment records processed.\n",
      "15400000 alignment records processed.\n",
      "15500000 alignment records processed.\n",
      "15600000 alignment records processed.\n",
      "15700000 alignment records processed.\n",
      "15800000 alignment records processed.\n",
      "15900000 alignment records processed.\n",
      "16000000 alignment records processed.\n",
      "16100000 alignment records processed.\n",
      "16200000 alignment records processed.\n",
      "16300000 alignment records processed.\n",
      "16400000 alignment records processed.\n",
      "16500000 alignment records processed.\n",
      "16600000 alignment records processed.\n",
      "16700000 alignment records processed.\n",
      "16800000 alignment records processed.\n",
      "16900000 alignment records processed.\n",
      "17000000 alignment records processed.\n",
      "17100000 alignment records processed.\n",
      "17200000 alignment records processed.\n",
      "17300000 alignment records processed.\n",
      "17400000 alignment records processed.\n",
      "17500000 alignment records processed.\n",
      "17600000 alignment records processed.\n",
      "17700000 alignment records processed.\n",
      "17800000 alignment records processed.\n",
      "17900000 alignment records processed.\n",
      "18000000 alignment records processed.\n",
      "18100000 alignment records processed.\n",
      "18200000 alignment records processed.\n",
      "18300000 alignment records processed.\n",
      "18400000 alignment records processed.\n",
      "18500000 alignment records processed.\n",
      "18573565 alignment records processed.\n",
      "\n",
      "real\t10m53.457s\n",
      "user\t10m44.723s\n",
      "sys\t0m8.530s\n",
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1872052 GFF lines processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "400000 alignment records processed.\n",
      "500000 alignment records processed.\n",
      "600000 alignment records processed.\n",
      "700000 alignment records processed.\n",
      "800000 alignment records processed.\n",
      "900000 alignment records processed.\n",
      "1000000 alignment records processed.\n",
      "1100000 alignment records processed.\n",
      "1200000 alignment records processed.\n",
      "1300000 alignment records processed.\n",
      "1400000 alignment records processed.\n",
      "1500000 alignment records processed.\n",
      "1600000 alignment records processed.\n",
      "1700000 alignment records processed.\n",
      "1800000 alignment records processed.\n",
      "1900000 alignment records processed.\n",
      "2000000 alignment records processed.\n",
      "2100000 alignment records processed.\n",
      "2200000 alignment records processed.\n",
      "2300000 alignment records processed.\n",
      "2400000 alignment records processed.\n",
      "2500000 alignment records processed.\n",
      "2600000 alignment records processed.\n",
      "2700000 alignment records processed.\n",
      "2800000 alignment records processed.\n",
      "2900000 alignment records processed.\n",
      "3000000 alignment records processed.\n",
      "3100000 alignment records processed.\n",
      "3200000 alignment records processed.\n",
      "3300000 alignment records processed.\n",
      "3400000 alignment records processed.\n",
      "3500000 alignment records processed.\n",
      "3600000 alignment records processed.\n",
      "3700000 alignment records processed.\n",
      "3800000 alignment records processed.\n",
      "3900000 alignment records processed.\n",
      "4000000 alignment records processed.\n",
      "4100000 alignment records processed.\n",
      "4200000 alignment records processed.\n",
      "4300000 alignment records processed.\n",
      "4400000 alignment records processed.\n",
      "4500000 alignment records processed.\n",
      "4600000 alignment records processed.\n",
      "4700000 alignment records processed.\n",
      "4800000 alignment records processed.\n",
      "4900000 alignment records processed.\n",
      "5000000 alignment records processed.\n",
      "5100000 alignment records processed.\n",
      "5200000 alignment records processed.\n",
      "5300000 alignment records processed.\n",
      "5400000 alignment records processed.\n",
      "5500000 alignment records processed.\n",
      "5600000 alignment records processed.\n",
      "5700000 alignment records processed.\n",
      "5800000 alignment records processed.\n",
      "5900000 alignment records processed.\n",
      "6000000 alignment records processed.\n",
      "6100000 alignment records processed.\n",
      "6200000 alignment records processed.\n",
      "6300000 alignment records processed.\n",
      "6400000 alignment records processed.\n",
      "6500000 alignment records processed.\n",
      "6600000 alignment records processed.\n",
      "6700000 alignment records processed.\n",
      "6800000 alignment records processed.\n",
      "6900000 alignment records processed.\n",
      "7000000 alignment records processed.\n",
      "7100000 alignment records processed.\n",
      "7200000 alignment records processed.\n",
      "7300000 alignment records processed.\n",
      "7400000 alignment records processed.\n",
      "7500000 alignment records processed.\n",
      "7600000 alignment records processed.\n",
      "7700000 alignment records processed.\n",
      "7800000 alignment records processed.\n",
      "7900000 alignment records processed.\n",
      "8000000 alignment records processed.\n",
      "8100000 alignment records processed.\n",
      "8200000 alignment records processed.\n",
      "8300000 alignment records processed.\n",
      "8400000 alignment records processed.\n",
      "8500000 alignment records processed.\n",
      "8600000 alignment records processed.\n",
      "8700000 alignment records processed.\n",
      "8800000 alignment records processed.\n",
      "8900000 alignment records processed.\n",
      "9000000 alignment records processed.\n",
      "9100000 alignment records processed.\n",
      "9200000 alignment records processed.\n",
      "9300000 alignment records processed.\n",
      "9400000 alignment records processed.\n",
      "9500000 alignment records processed.\n",
      "9600000 alignment records processed.\n",
      "9700000 alignment records processed.\n",
      "9800000 alignment records processed.\n",
      "9900000 alignment records processed.\n",
      "10000000 alignment records processed.\n",
      "10100000 alignment records processed.\n",
      "10200000 alignment records processed.\n",
      "10300000 alignment records processed.\n",
      "10400000 alignment records processed.\n",
      "10500000 alignment records processed.\n",
      "10600000 alignment records processed.\n",
      "10700000 alignment records processed.\n",
      "10800000 alignment records processed.\n",
      "10900000 alignment records processed.\n",
      "11000000 alignment records processed.\n",
      "11100000 alignment records processed.\n",
      "11200000 alignment records processed.\n",
      "11300000 alignment records processed.\n",
      "11400000 alignment records processed.\n",
      "11500000 alignment records processed.\n",
      "11600000 alignment records processed.\n",
      "11700000 alignment records processed.\n",
      "11800000 alignment records processed.\n",
      "11900000 alignment records processed.\n",
      "12000000 alignment records processed.\n",
      "12100000 alignment records processed.\n",
      "12200000 alignment records processed.\n",
      "12300000 alignment records processed.\n",
      "12400000 alignment records processed.\n",
      "12500000 alignment records processed.\n",
      "12600000 alignment records processed.\n",
      "12700000 alignment records processed.\n",
      "12800000 alignment records processed.\n",
      "12900000 alignment records processed.\n",
      "13000000 alignment records processed.\n",
      "13100000 alignment records processed.\n",
      "13200000 alignment records processed.\n",
      "13300000 alignment records processed.\n",
      "13320505 alignment records processed.\n",
      "\n",
      "real\t8m53.772s\n",
      "user\t8m39.533s\n",
      "sys\t0m8.470s\n",
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1872052 GFF lines processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "400000 alignment records processed.\n",
      "500000 alignment records processed.\n",
      "600000 alignment records processed.\n",
      "700000 alignment records processed.\n",
      "800000 alignment records processed.\n",
      "900000 alignment records processed.\n",
      "1000000 alignment records processed.\n",
      "1100000 alignment records processed.\n",
      "1200000 alignment records processed.\n",
      "1300000 alignment records processed.\n",
      "1400000 alignment records processed.\n",
      "1500000 alignment records processed.\n",
      "1600000 alignment records processed.\n",
      "1700000 alignment records processed.\n",
      "1800000 alignment records processed.\n",
      "1900000 alignment records processed.\n",
      "2000000 alignment records processed.\n",
      "2100000 alignment records processed.\n",
      "2200000 alignment records processed.\n",
      "2300000 alignment records processed.\n",
      "2400000 alignment records processed.\n",
      "2500000 alignment records processed.\n",
      "2600000 alignment records processed.\n",
      "2700000 alignment records processed.\n",
      "2800000 alignment records processed.\n",
      "2900000 alignment records processed.\n",
      "3000000 alignment records processed.\n",
      "3100000 alignment records processed.\n",
      "3200000 alignment records processed.\n",
      "3300000 alignment records processed.\n",
      "3400000 alignment records processed.\n",
      "3500000 alignment records processed.\n",
      "3600000 alignment records processed.\n",
      "3700000 alignment records processed.\n",
      "3800000 alignment records processed.\n",
      "3900000 alignment records processed.\n",
      "4000000 alignment records processed.\n",
      "4100000 alignment records processed.\n",
      "4200000 alignment records processed.\n",
      "4300000 alignment records processed.\n",
      "4400000 alignment records processed.\n",
      "4500000 alignment records processed.\n",
      "4600000 alignment records processed.\n",
      "4700000 alignment records processed.\n",
      "4800000 alignment records processed.\n",
      "4900000 alignment records processed.\n",
      "5000000 alignment records processed.\n",
      "5100000 alignment records processed.\n",
      "5200000 alignment records processed.\n",
      "5300000 alignment records processed.\n",
      "5400000 alignment records processed.\n",
      "5500000 alignment records processed.\n",
      "5600000 alignment records processed.\n",
      "5700000 alignment records processed.\n",
      "5800000 alignment records processed.\n",
      "5900000 alignment records processed.\n",
      "6000000 alignment records processed.\n",
      "6100000 alignment records processed.\n",
      "6200000 alignment records processed.\n",
      "6300000 alignment records processed.\n",
      "6400000 alignment records processed.\n",
      "6500000 alignment records processed.\n",
      "6600000 alignment records processed.\n",
      "6700000 alignment records processed.\n",
      "6800000 alignment records processed.\n",
      "6900000 alignment records processed.\n",
      "7000000 alignment records processed.\n",
      "7100000 alignment records processed.\n",
      "7200000 alignment records processed.\n",
      "7300000 alignment records processed.\n",
      "7400000 alignment records processed.\n",
      "7500000 alignment records processed.\n",
      "7600000 alignment records processed.\n",
      "7700000 alignment records processed.\n",
      "7800000 alignment records processed.\n",
      "7900000 alignment records processed.\n",
      "8000000 alignment records processed.\n",
      "8100000 alignment records processed.\n",
      "8200000 alignment records processed.\n",
      "8300000 alignment records processed.\n",
      "8400000 alignment records processed.\n",
      "8500000 alignment records processed.\n",
      "8600000 alignment records processed.\n",
      "8700000 alignment records processed.\n",
      "8800000 alignment records processed.\n",
      "8900000 alignment records processed.\n",
      "9000000 alignment records processed.\n",
      "9100000 alignment records processed.\n",
      "9200000 alignment records processed.\n",
      "9300000 alignment records processed.\n",
      "9400000 alignment records processed.\n",
      "9500000 alignment records processed.\n",
      "9600000 alignment records processed.\n",
      "9700000 alignment records processed.\n",
      "9800000 alignment records processed.\n",
      "9900000 alignment records processed.\n",
      "10000000 alignment records processed.\n",
      "10100000 alignment records processed.\n",
      "10200000 alignment records processed.\n",
      "10300000 alignment records processed.\n",
      "10400000 alignment records processed.\n",
      "10500000 alignment records processed.\n",
      "10600000 alignment records processed.\n",
      "10700000 alignment records processed.\n",
      "10800000 alignment records processed.\n",
      "10900000 alignment records processed.\n",
      "11000000 alignment records processed.\n",
      "11100000 alignment records processed.\n",
      "11200000 alignment records processed.\n",
      "11300000 alignment records processed.\n",
      "11400000 alignment records processed.\n",
      "11500000 alignment records processed.\n",
      "11600000 alignment records processed.\n",
      "11700000 alignment records processed.\n",
      "11800000 alignment records processed.\n",
      "11900000 alignment records processed.\n",
      "12000000 alignment records processed.\n",
      "12100000 alignment records processed.\n",
      "12200000 alignment records processed.\n",
      "12300000 alignment records processed.\n",
      "12400000 alignment records processed.\n",
      "12500000 alignment records processed.\n",
      "12600000 alignment records processed.\n",
      "12700000 alignment records processed.\n",
      "12800000 alignment records processed.\n",
      "12900000 alignment records processed.\n",
      "13000000 alignment records processed.\n",
      "13100000 alignment records processed.\n",
      "13200000 alignment records processed.\n",
      "13300000 alignment records processed.\n",
      "13400000 alignment records processed.\n",
      "13500000 alignment records processed.\n",
      "13600000 alignment records processed.\n",
      "13700000 alignment records processed.\n",
      "13800000 alignment records processed.\n",
      "13900000 alignment records processed.\n",
      "14000000 alignment records processed.\n",
      "14100000 alignment records processed.\n",
      "14200000 alignment records processed.\n",
      "14300000 alignment records processed.\n",
      "14400000 alignment records processed.\n",
      "14500000 alignment records processed.\n",
      "14600000 alignment records processed.\n",
      "14700000 alignment records processed.\n",
      "14800000 alignment records processed.\n",
      "14900000 alignment records processed.\n",
      "15000000 alignment records processed.\n",
      "15100000 alignment records processed.\n",
      "15200000 alignment records processed.\n",
      "15300000 alignment records processed.\n",
      "15400000 alignment records processed.\n",
      "15500000 alignment records processed.\n",
      "15600000 alignment records processed.\n",
      "15700000 alignment records processed.\n",
      "15800000 alignment records processed.\n",
      "15900000 alignment records processed.\n",
      "16000000 alignment records processed.\n",
      "16100000 alignment records processed.\n",
      "16200000 alignment records processed.\n",
      "16300000 alignment records processed.\n",
      "16400000 alignment records processed.\n",
      "16500000 alignment records processed.\n",
      "16600000 alignment records processed.\n",
      "16700000 alignment records processed.\n",
      "16800000 alignment records processed.\n",
      "16900000 alignment records processed.\n",
      "17000000 alignment records processed.\n",
      "17100000 alignment records processed.\n",
      "17200000 alignment records processed.\n",
      "17300000 alignment records processed.\n",
      "17400000 alignment records processed.\n",
      "17500000 alignment records processed.\n",
      "17600000 alignment records processed.\n",
      "17700000 alignment records processed.\n",
      "17800000 alignment records processed.\n",
      "17900000 alignment records processed.\n",
      "18000000 alignment records processed.\n",
      "18100000 alignment records processed.\n",
      "18200000 alignment records processed.\n",
      "18300000 alignment records processed.\n",
      "18400000 alignment records processed.\n",
      "18500000 alignment records processed.\n",
      "18600000 alignment records processed.\n",
      "18700000 alignment records processed.\n",
      "18800000 alignment records processed.\n",
      "18900000 alignment records processed.\n",
      "19000000 alignment records processed.\n",
      "19100000 alignment records processed.\n",
      "19200000 alignment records processed.\n",
      "19300000 alignment records processed.\n",
      "19400000 alignment records processed.\n",
      "19500000 alignment records processed.\n",
      "19600000 alignment records processed.\n",
      "19700000 alignment records processed.\n",
      "19800000 alignment records processed.\n",
      "19900000 alignment records processed.\n",
      "20000000 alignment records processed.\n",
      "20100000 alignment records processed.\n",
      "20200000 alignment records processed.\n",
      "20300000 alignment records processed.\n",
      "20400000 alignment records processed.\n",
      "20500000 alignment records processed.\n",
      "20600000 alignment records processed.\n",
      "20700000 alignment records processed.\n",
      "20800000 alignment records processed.\n",
      "20900000 alignment records processed.\n",
      "21000000 alignment records processed.\n",
      "21100000 alignment records processed.\n",
      "21159606 alignment records processed.\n",
      "\n",
      "real\t13m29.368s\n",
      "user\t13m8.200s\n",
      "sys\t0m15.841s\n"
     ]
    }
   ],
   "source": [
    "!time htseq-count --format=sam --stranded=no SRR3414635.uniq.sam  gencode.vM25.annotation.gtf > SRR3414635.counts\n",
    "!time htseq-count --format=sam --stranded=no SRR3414636.uniq.sam  gencode.vM25.annotation.gtf > SRR3414636.counts\n",
    "!time htseq-count --format=sam --stranded=no SRR3414637.uniq.sam  gencode.vM25.annotation.gtf > SRR3414637.counts\n",
    "!time htseq-count --format=sam --stranded=no SRR3414629.uniq.sam  gencode.vM25.annotation.gtf > SRR3414629.counts\n",
    "!time htseq-count --format=sam --stranded=no SRR3414630.uniq.sam  gencode.vM25.annotation.gtf > SRR3414630.counts\n",
    "!time htseq-count --format=sam --stranded=no SRR3414631.uniq.sam  gencode.vM25.annotation.gtf > SRR3414631.counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHTMa6RlA_m4"
   },
   "source": [
    "* Смотрим сколько чтений не удалось приписать ни одному гену:\n",
    "* `__no_feature 1332692` – столько чтений соответствует участкам генома, где не аннотировано ни одного экзона\n",
    "* `__ambiguous 735108` – столько чтений могут принадлежать разным генам\n",
    "* Более подробно про такие случаи можно посмотреть в описании HTSeq-count - https://htseq.readthedocs.io/en/release_0.11.1/count.html\n",
    "* Итого, общее число чтений, соответствующих хотя бы одному гену равно:\n",
    "17825380 – 1332692 – 735108 = 15757580\n",
    "* Для каждого образца приводим эту статистику в отчете на Github\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvENnVBnisX1",
    "outputId": "50ec86e3-2503-4a19-a08a-80a272b3f97b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__no_feature\t1406679\n",
      "__ambiguous\t767361\n",
      "__too_low_aQual\t0\n",
      "__not_aligned\t0\n",
      "__alignment_not_unique\t0\n"
     ]
    }
   ],
   "source": [
    "! grep '^__' SRR3414635.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IAsjKCRLE5h",
    "outputId": "01b43b78-0c31-4608-882f-32fa66ea0e04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__no_feature\t1347210\n",
      "__ambiguous\t742802\n",
      "__too_low_aQual\t0\n",
      "__not_aligned\t0\n",
      "__alignment_not_unique\t0\n"
     ]
    }
   ],
   "source": [
    "! grep '^__' SRR3414636.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIZD7MZjLEwp",
    "outputId": "520b4284-8b79-40cd-fa43-e53281243460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__no_feature\t1411488\n",
      "__ambiguous\t717538\n",
      "__too_low_aQual\t0\n",
      "__not_aligned\t0\n",
      "__alignment_not_unique\t0\n"
     ]
    }
   ],
   "source": [
    "! grep '^__' SRR3414637.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQdbKFZGLEmx",
    "outputId": "3932c9ec-4977-4462-db6c-02ba1c758cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__no_feature\t1620359\n",
      "__ambiguous\t728893\n",
      "__too_low_aQual\t0\n",
      "__not_aligned\t0\n",
      "__alignment_not_unique\t0\n"
     ]
    }
   ],
   "source": [
    "! grep '^__' SRR3414629.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-LcHZbMLEDV",
    "outputId": "6df3e1f1-fbb4-44a8-d3cb-81611c24dd10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__no_feature\t1251763\n",
      "__ambiguous\t484967\n",
      "__too_low_aQual\t0\n",
      "__not_aligned\t0\n",
      "__alignment_not_unique\t0\n"
     ]
    }
   ],
   "source": [
    "! grep '^__' SRR3414630.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7his-KoLDMw",
    "outputId": "f0cc3092-e204-4adb-b150-61e38eeb3148"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__no_feature\t1718354\n",
      "__ambiguous\t827751\n",
      "__too_low_aQual\t0\n",
      "__not_aligned\t0\n",
      "__alignment_not_unique\t0\n"
     ]
    }
   ],
   "source": [
    "! grep '^__' SRR3414631.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEaQicYBLWXz",
    "outputId": "279e84e9-a2ef-4f77-e0a3-86d7f0d535a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "общее число чтений для SRR3414635, соответствующих хотя бы одному гену равно: 16463013\n",
      "общее число чтений для SRR3414636, соответствующих хотя бы одному гену равно: 15942667\n",
      "общее число чтений для SRR3414637, соответствующих хотя бы одному гену равно: 15914380\n",
      "общее число чтений для SRR3414629, соответствующих хотя бы одному гену равно: 16224313\n",
      "общее число чтений для SRR3414630, соответствующих хотя бы одному гену равно: 11583775\n",
      "общее число чтений для SRR3414631, соответствующих хотя бы одному гену равно: 18613501\n"
     ]
    }
   ],
   "source": [
    "print(f'общее число чтений для SRR3414635, соответствующих хотя бы одному гену равно: {18637053 - 1406679 - 767361}')\n",
    "print(f'общее число чтений для SRR3414636, соответствующих хотя бы одному гену равно: {18032679 - 1347210 - 742802}')\n",
    "print(f'общее число чтений для SRR3414637, соответствующих хотя бы одному гену равно: {18043406 - 1411488 - 717538}')\n",
    "print(f'общее число чтений для SRR3414629, соответствующих хотя бы одному гену равно: {18573565 - 1620359 - 728893}')\n",
    "print(f'общее число чтений для SRR3414630, соответствующих хотя бы одному гену равно: {13320505 - 1251763 - 484967}')\n",
    "print(f'общее число чтений для SRR3414631, соответствующих хотя бы одному гену равно: {21159606 - 1718354 - 827751}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQ-ryqO0BiDp"
   },
   "source": [
    "* Объединям все файлы .counts по генам в один общий файл `ALL.counts`.\n",
    "* В качестве заголовка для каждого образца указывать не его SRR id, а c1, c2, c3 для контрольных образцов и r1, r2, r3 для перепрограммированных образцов.\n",
    "* Загружаем полученный ALL.counts файл в Github репозиторий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zfINZNRcL-9C"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "counts = []\n",
    "for sample in [[\"SRR3414635\", \"c1\"], [\"SRR3414636\", \"c2\"], [\"SRR3414637\", \"c3\"],\n",
    "               [\"SRR3414629\", \"r1\"], [\"SRR3414630\", \"r2\"], [\"SRR3414631\", \"r3\"]]:\n",
    "    counts.append(pd.read_csv(f\"{sample[0]}.counts\", sep=\"\\t\", names=[sample[1]]))\n",
    "\n",
    "\"\"\"\n",
    "обрезаем 5 лишных строки с\n",
    "__no_feature\n",
    "__ambiguous\n",
    "__too_low_aQual\n",
    "__not_aligned\n",
    "__alignment_not_unique\n",
    "\n",
    "\"\"\"\n",
    "counts_1 = pd.concat(counts, axis=1)\n",
    "all_counts = counts_1[:-5]\n",
    "\n",
    "all_counts.to_csv(\"ALL.counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "vy-WKaaMMNrU",
    "outputId": "542ce143-7d1b-4804-de2b-fa59011c3323"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000000001.4</th>\n",
       "      <td>3466</td>\n",
       "      <td>3532</td>\n",
       "      <td>4078</td>\n",
       "      <td>4507</td>\n",
       "      <td>3964</td>\n",
       "      <td>5757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000000003.15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000000028.15</th>\n",
       "      <td>152</td>\n",
       "      <td>137</td>\n",
       "      <td>152</td>\n",
       "      <td>348</td>\n",
       "      <td>275</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000000031.16</th>\n",
       "      <td>55721</td>\n",
       "      <td>48392</td>\n",
       "      <td>56187</td>\n",
       "      <td>64722</td>\n",
       "      <td>33333</td>\n",
       "      <td>65188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000000037.17</th>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>53</td>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000118655.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000118656.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000118657.1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000118658.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000118659.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55401 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          c1     c2     c3     r1     r2     r3\n",
       "ENSMUSG00000000001.4    3466   3532   4078   4507   3964   5757\n",
       "ENSMUSG00000000003.15      0      0      0      0      0      0\n",
       "ENSMUSG00000000028.15    152    137    152    348    275    472\n",
       "ENSMUSG00000000031.16  55721  48392  56187  64722  33333  65188\n",
       "ENSMUSG00000000037.17     43     44     53     79     70     92\n",
       "...                      ...    ...    ...    ...    ...    ...\n",
       "ENSMUSG00000118655.1       0      0      0      0      1      1\n",
       "ENSMUSG00000118656.1       0      0      0      0      0      0\n",
       "ENSMUSG00000118657.1       0      1      0      2      0      4\n",
       "ENSMUSG00000118658.1       0      0      0      0      0      0\n",
       "ENSMUSG00000118659.1       0      0      0      0      0      0\n",
       "\n",
       "[55401 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2x24rL3StIt"
   },
   "source": [
    "Сделаем файл с данными для следующей части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "ateqE-NASr6c",
    "outputId": "1c553f6c-ac11-4ef9-c993-c07ab5241711"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c1</th>\n",
       "      <td>SRR3414635</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2</th>\n",
       "      <td>SRR3414636</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c3</th>\n",
       "      <td>SRR3414637</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1</th>\n",
       "      <td>SRR3414629</td>\n",
       "      <td>reprogramming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>SRR3414630</td>\n",
       "      <td>reprogramming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r3</th>\n",
       "      <td>SRR3414631</td>\n",
       "      <td>reprogramming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id      condition\n",
       "c1  SRR3414635        control\n",
       "c2  SRR3414636        control\n",
       "c3  SRR3414637        control\n",
       "r1  SRR3414629  reprogramming\n",
       "r2  SRR3414630  reprogramming\n",
       "r3  SRR3414631  reprogramming"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'id':['SRR3414635', 'SRR3414636', 'SRR3414637', 'SRR3414629', 'SRR3414630', 'SRR3414631'], 'condition':['control', 'control', 'control', 'reprogramming', 'reprogramming', 'reprogramming']}\n",
    "ALL_info = pd.DataFrame(data, index =['c1', 'c2', 'c3', 'r1', 'r2', 'r3'])\n",
    "ALL_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "uKEY6DV1TW3-",
    "outputId": "587b4a08-bc69-442d-95e3-d3e9e8a5126b"
   },
   "outputs": [],
   "source": [
    "ALL_info.to_csv('ALL(6).info')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lyy148LnGPa1"
   },
   "source": [
    "В итоге получили файл с общим числом чтений для всех генов ALL.counts и файл с общей информацией ALL.info, которые понадобятся нам в следующей части дз"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
